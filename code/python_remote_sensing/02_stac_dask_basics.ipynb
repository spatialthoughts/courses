{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a244534-c0a1-41b4-9f73-2087eb72b030",
      "metadata": {
        "id": "9a244534-c0a1-41b4-9f73-2087eb72b030"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this section, we will learn the basics of querying cloud-hosted data via [STAC](https://stacspec.org/en) and leverage parallel computing via [Dask](https://tutorial.xarray.dev/intermediate/xarray_and_dask.html).\n",
        "\n",
        "We will learn how to query a catalog of Sentinel-2 images to find the least-cloudy scene over a chosen area, visualize it and download it as a GeoTIFF file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c4204d0-acda-418f-b38a-7d5f2be15eca",
      "metadata": {
        "id": "2c4204d0-acda-418f-b38a-7d5f2be15eca"
      },
      "source": [
        "## Setup and Data Download\n",
        "\n",
        "The following blocks of code will install the required packages and download the datasets to your Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jf7cnFbts_ES",
      "metadata": {
        "id": "jf7cnFbts_ES"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install pystac-client odc-stac rioxarray dask jupyter-server-proxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe6c71dd-37df-47af-9019-d012cc9b5e59",
      "metadata": {
        "id": "fe6c71dd-37df-47af-9019-d012cc9b5e59"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pystac_client\n",
        "from odc import stac\n",
        "import xarray as xr\n",
        "import rioxarray as rxr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dA58tdUJJAni",
      "metadata": {
        "id": "dA58tdUJJAni"
      },
      "source": [
        "## Dask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wdl41A5UI7vY",
      "metadata": {
        "id": "Wdl41A5UI7vY"
      },
      "source": [
        "[`Dask`](https://www.dask.org/) is a python library to run your computation in parallel across many machines. Dask has built-in support for key geospatial packages like XArray and Pandas allowing you to scale your computation easily. You can choose to run your code in parallel on your laptop, a machine in the cloud, local or cloud cluster of machines etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I2KA7L44UDyj",
      "metadata": {
        "id": "I2KA7L44UDyj"
      },
      "outputs": [],
      "source": [
        "from dask.distributed import Client\n",
        "client = Client()  # set up local cluster on the machine\n",
        "client"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KZN-5NC0UGxM",
      "metadata": {
        "id": "KZN-5NC0UGxM"
      },
      "source": [
        "If you are running this notebook in Colab, you will need to create and use a proxy URL to see the dashboard running on the local server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LGoGPPD_UFZA",
      "metadata": {
        "id": "LGoGPPD_UFZA"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import output\n",
        "    port_to_expose = 8787  # This is the default port for Dask dashboard\n",
        "    print(output.eval_js(f'google.colab.kernel.proxyPort({port_to_expose})'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qYm2b2t7ut8N",
      "metadata": {
        "id": "qYm2b2t7ut8N"
      },
      "source": [
        "## Spatio Temporal Asset Catalog (STAC)\n",
        "\n",
        "Spatio Temporal Asset Catalog (STAC) is an open standard for specifying and querying geospatial data. Data provider can share catalogs of satellite imagery ,climate datasets, LIDAR data, vector data etc. and specify asset metadata according to the STAC specifications. All STAC catalogs can be queried to find matching assets by time, location or metadata.\n",
        "\n",
        "\n",
        "You can browse all available catalogs at https://stacindex.org/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nL8kqCYovK1S",
      "metadata": {
        "id": "nL8kqCYovK1S"
      },
      "source": [
        "Let's use [Earth Search by Element 84](https://stacindex.org/catalogs/earth-search#/) STAC API Catalog to look for items from the sentinel-2-l2a collection on AWS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CQmDtdO7KXZ8",
      "metadata": {
        "id": "CQmDtdO7KXZ8"
      },
      "outputs": [],
      "source": [
        "catalog = pystac_client.Client.open(\n",
        "    'https://earth-search.aws.element84.com/v1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DfeU1L0HCPN3",
      "metadata": {
        "id": "DfeU1L0HCPN3"
      },
      "source": [
        "We define a location and time of interest to get some satellite imagery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yFB6fP_Cu0Rw",
      "metadata": {
        "id": "yFB6fP_Cu0Rw"
      },
      "outputs": [],
      "source": [
        "latitude = 27.163\n",
        "longitude = 82.608\n",
        "year = 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Eyw63wuevOp-",
      "metadata": {
        "id": "Eyw63wuevOp-"
      },
      "outputs": [],
      "source": [
        "# Define a small bounding box around the chosen point\n",
        "km2deg = 1.0 / 111\n",
        "x, y = (longitude, latitude)\n",
        "r = 1 * km2deg  # radius in degrees\n",
        "bbox = (x - r, y - r, x + r, y + r)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_H_dLmj7KiJO",
      "metadata": {
        "id": "_H_dLmj7KiJO"
      },
      "source": [
        "Search the catalog for matching items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1FdQxCyGKk2l",
      "metadata": {
        "id": "1FdQxCyGKk2l"
      },
      "outputs": [],
      "source": [
        "search = catalog.search(\n",
        "    collections=['sentinel-2-c1-l2a'],\n",
        "    bbox=bbox,\n",
        "    datetime=f'{year}'\n",
        ")\n",
        "items = search.item_collection()\n",
        "items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8x9TV8dWKvPV",
      "metadata": {
        "id": "8x9TV8dWKvPV"
      },
      "source": [
        "We can apply some additional metadata filters to look for images with less cloud cover and granules with less nodata pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y9nSaSiFK0hK",
      "metadata": {
        "id": "y9nSaSiFK0hK"
      },
      "outputs": [],
      "source": [
        "search = catalog.search(\n",
        "    collections=['sentinel-2-c1-l2a'],\n",
        "    bbox=bbox,\n",
        "    datetime=f'{year}',\n",
        "    query={'eo:cloud_cover': {'lt': 30}, 's2:nodata_pixel_percentage': {'lt': 10}}\n",
        ")\n",
        "items = search.item_collection()\n",
        "items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XCNPD7qXLFPL",
      "metadata": {
        "id": "XCNPD7qXLFPL"
      },
      "source": [
        "We can also sort the results by some metadata. Here we sort by cloud cover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l68ZjcOPZGAZ",
      "metadata": {
        "id": "l68ZjcOPZGAZ"
      },
      "outputs": [],
      "source": [
        "search = catalog.search(\n",
        "    collections=['sentinel-2-c1-l2a'],\n",
        "    bbox=bbox,\n",
        "    datetime=f'{year}',\n",
        "    query={'eo:cloud_cover': {'lt': 30}, 's2:nodata_pixel_percentage': {'lt': 10}},\n",
        "    sortby=[{'field': 'properties.eo:cloud_cover', 'direction': 'asc'}]\n",
        "\n",
        ")\n",
        "items = search.item_collection()\n",
        "items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lpzNYT64LZk4",
      "metadata": {
        "id": "lpzNYT64LZk4"
      },
      "source": [
        "## Load STAC Images to XArray"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15iTJmV5CwnP",
      "metadata": {
        "id": "15iTJmV5CwnP"
      },
      "source": [
        "Load the matching images as a XArray Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y7a0SNP30yTd",
      "metadata": {
        "id": "Y7a0SNP30yTd"
      },
      "outputs": [],
      "source": [
        "ds = stac.load(\n",
        "    items,\n",
        "    bands=['red', 'green', 'blue', 'nir'],\n",
        "    resolution=10,\n",
        "    chunks={},  # <-- use Dask\n",
        "    groupby='solar_day',\n",
        "    preserve_original_order=True\n",
        ")\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ANUXKKYkMH61",
      "metadata": {
        "id": "ANUXKKYkMH61"
      },
      "source": [
        "Use[ `xarray.Dataset.nbytes`](https://docs.xarray.dev/en/latest/generated/xarray.Dataset.nbytes.html) property to check the size of the loaded dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Aq2WX9RdZzWT",
      "metadata": {
        "id": "Aq2WX9RdZzWT"
      },
      "outputs": [],
      "source": [
        "print(f'DataSet size: {ds.nbytes/1e6:.2f} MB.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U1Yjq2sNQEib",
      "metadata": {
        "id": "U1Yjq2sNQEib"
      },
      "source": [
        "## Select a Single Scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QR9Gqm0QMnM7",
      "metadata": {
        "id": "QR9Gqm0QMnM7"
      },
      "source": [
        "Let's work with a single scene for now. We will use the first item from our search (the least cloudy scene). When the items are loaded as a XArray Dataset, the `time` dimension is sorted. We get the timestamp of the least cloudy scene and select it from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bxmTBnyvfkBY",
      "metadata": {
        "id": "bxmTBnyvfkBY"
      },
      "outputs": [],
      "source": [
        "timestamp = pd.to_datetime(items[0].properties['datetime']).tz_convert(None)\n",
        "scene = ds.sel(time=timestamp)\n",
        "scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r-qSz1dmfw8g",
      "metadata": {
        "id": "r-qSz1dmfw8g"
      },
      "outputs": [],
      "source": [
        "print(f'Scene size: {scene.nbytes/1e6:.2f} MB.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Ub8H4FLNS3S",
      "metadata": {
        "id": "2Ub8H4FLNS3S"
      },
      "source": [
        "This scene is small enough to fit into RAM, so let's call `compute()` to load this into memory. Dask will query the cloud-hosted dataset to fetch the required pixels. As we setup a Dask LocalCluster, the process will be paralellized across all available cores of the machine. Once you run the cell, look at the Dask Diagnostic Dashboard to see the data processing in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3Gp8L7of18k",
      "metadata": {
        "id": "b3Gp8L7of18k"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "scene = scene.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O8zkWD47N3vo",
      "metadata": {
        "id": "O8zkWD47N3vo"
      },
      "outputs": [],
      "source": [
        "scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vgefI7nTuRqb",
      "metadata": {
        "id": "vgefI7nTuRqb"
      },
      "source": [
        "The Sentinel-2 scenes come with NoData value of 0. So we set the correct NoData value before further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1mIFrJ0GuUbx",
      "metadata": {
        "id": "1mIFrJ0GuUbx"
      },
      "outputs": [],
      "source": [
        "scene = scene.where(scene != 0)\n",
        "scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7IrzpuM13jvM",
      "metadata": {
        "id": "7IrzpuM13jvM"
      },
      "source": [
        "Each band of the scene is saved with integer pixel values (data type `uint16`). This help save the storage cost as storing the reflectance values as floating point numbers (data type `float64`) requires more storage. We need to convert the raw pixel values to reflectances by applying the *scale* and *offset* values. The [Earth Search STAC API](https://github.com/Element84/earth-search) does not apply the scale/offset automatically to Sentinel-2 scene and they are supplied in the `raster:bands` metadata for each band. The scale and offset for sentinel-2 scenes captured after Jan 25, 2022 is `0.0001` and `-0.1` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eGAgG5Bb4uDn",
      "metadata": {
        "id": "eGAgG5Bb4uDn"
      },
      "outputs": [],
      "source": [
        "scale = 0.0001\n",
        "offset = -0.1\n",
        "scene = scene*scale + offset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EtWVe_TNN-V5",
      "metadata": {
        "id": "EtWVe_TNN-V5"
      },
      "source": [
        "## Visualize the Scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hCzpJQLjOKpO",
      "metadata": {
        "id": "hCzpJQLjOKpO"
      },
      "source": [
        "To visualize our Dataset, we first convert it to a DataArray using the `to_array()` method. All the variables will be converted to a new dimension. Since our variables are image bands, we give the name of the new dimesion as band.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QrjqYog1j7Wj",
      "metadata": {
        "id": "QrjqYog1j7Wj"
      },
      "outputs": [],
      "source": [
        "scene_da = scene.to_array('band')\n",
        "scene_da"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KwLtwED1OPUi",
      "metadata": {
        "id": "KwLtwED1OPUi"
      },
      "source": [
        "We can create a low-resolution preview by resampling the DataArray from its native resolution. The raster metadata is stored in the [rio accessor](https://corteva.github.io/rioxarray/stable/rioxarray.html#rioxarray-rio-accessors). This is enabled by the `rioxarray` library which provides geospatial functions on top of xarray."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yKpGIoqeOwzR",
      "metadata": {
        "id": "yKpGIoqeOwzR"
      },
      "outputs": [],
      "source": [
        "print('CRS:', scene_da.rio.crs)\n",
        "print('Resolution:', scene_da.rio.resolution())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZvrXP8uOPFiW",
      "metadata": {
        "id": "ZvrXP8uOPFiW"
      },
      "source": [
        "This is a fairly large scene with a lot of pixels. For visualizing, we resample it to a lower resolution preview. When plotting the image, the `robust=True` option applies a *98-percentile* stretch to find the optimal min/max values for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K1LBGnehgDNL",
      "metadata": {
        "id": "K1LBGnehgDNL"
      },
      "outputs": [],
      "source": [
        "preview = scene_da.rio.reproject(\n",
        "    scene_da.rio.crs, resolution=300\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "fig.set_size_inches(5,5)\n",
        "preview.sel(band=['red', 'green', 'blue']).plot.imshow(\n",
        "    ax=ax,\n",
        "    robust=True)\n",
        "ax.set_title('RGB Visualization')\n",
        "ax.set_axis_off()\n",
        "ax.set_aspect('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KyCU3Hs6WPpn",
      "metadata": {
        "id": "KyCU3Hs6WPpn"
      },
      "source": [
        "## Save the Scene to Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UWWTQBvSWO_n",
      "metadata": {
        "id": "UWWTQBvSWO_n"
      },
      "outputs": [],
      "source": [
        "scene_id = items[0].id\n",
        "output_da = scene_da.sel(band=['red', 'green', 'blue'])\n",
        "output_file = f'{scene_id}.tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KrCBniRTPfoD",
      "metadata": {
        "id": "KrCBniRTPfoD"
      },
      "source": [
        "Rather than saving it to the temporary machine where Colab is running, we can save it to our own Google Drive. This will ensure the image will be available to us even after existing Google Colab.\n",
        "\n",
        "Run the following cell to authenticate and mount the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0kaRA4MkjhQ",
      "metadata": {
        "id": "f0kaRA4MkjhQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FN-taBQGks9X",
      "metadata": {
        "id": "FN-taBQGks9X"
      },
      "outputs": [],
      "source": [
        "drive_folder_root = '/content/drive/MyDrive'\n",
        "output_file_path = os.path.join(drive_folder_root, output_file)\n",
        "output_da.rio.to_raster(output_file_path, compress='LZW')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
