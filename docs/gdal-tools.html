<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ujaval Gandhi" />


<title>Mastering GDAL Tools (Full Course Material)</title>

<script src="site_libs/header-attrs-2.10/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PDGF11RK4Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PDGF11RK4Z');
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>







<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Courses</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="http://spatialthoughts.com">Back to Main Site</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="#">Back to Top</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Mastering GDAL Tools (Full Course
Material)</h1>
<h3 class="subtitle">A practical hands-on introduction to GDAL and OGR
command-line programs</h3>
<h4 class="author">Ujaval Gandhi</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a></li>
<li><a href="#setting-up-the-environment"
id="toc-setting-up-the-environment">Setting up the Environment</a>
<ul>
<li><a href="#install-gdal" id="toc-install-gdal">Install GDAL</a></li>
<li><a href="#install-qgis" id="toc-install-qgis">Install QGIS</a></li>
</ul></li>
<li><a href="#download-the-data-package"
id="toc-download-the-data-package">Download the Data Package</a></li>
<li><a href="#get-the-course-videos" id="toc-get-the-course-videos">Get
the Course Videos</a>
<ul>
<li><a href="#youtube" id="toc-youtube">YouTube</a></li>
<li><a href="#vimeo" id="toc-vimeo">Vimeo</a></li>
</ul></li>
<li><a href="#getting-familiar-with-the-command-prompt"
id="toc-getting-familiar-with-the-command-prompt">Getting Familiar with
the Command Prompt</a></li>
<li><a href="#gdal-tools" id="toc-gdal-tools">1. GDAL Tools</a>
<ul>
<li><a href="#basic-raster-processing"
id="toc-basic-raster-processing">1.1 Basic Raster Processing</a></li>
<li><a href="#processing-elevation-data"
id="toc-processing-elevation-data">1.2 Processing Elevation
Data</a></li>
<li><a href="#processing-aerial-imagery"
id="toc-processing-aerial-imagery">1.3 Processing Aerial
Imagery</a></li>
<li><a href="#processing-satellite-imagery"
id="toc-processing-satellite-imagery">1.4 Processing Satellite
Imagery</a></li>
<li><a href="#processing-wms-layers" id="toc-processing-wms-layers">1.5
Processing WMS Layers</a></li>
<li><a href="#georeferencing" id="toc-georeferencing">1.6
Georeferencing</a></li>
<li><a href="#assignment" id="toc-assignment">Assignment</a></li>
</ul></li>
<li><a href="#ogr-tools" id="toc-ogr-tools">2. OGR Tools</a>
<ul>
<li><a href="#etl-basics" id="toc-etl-basics">2.1 ETL Basics</a></li>
<li><a href="#merging-vector-files" id="toc-merging-vector-files">2.2
Merging Vector Files</a></li>
<li><a href="#geoprocessing-and-spatial-queries"
id="toc-geoprocessing-and-spatial-queries">2.3 Geoprocessing and Spatial
Queries</a></li>
</ul></li>
<li><a href="#running-commands-in-batch"
id="toc-running-commands-in-batch">3. Running commands in batch</a></li>
<li><a href="#automating-and-scheduling-gdalogr-jobs"
id="toc-automating-and-scheduling-gdalogr-jobs">4. Automating and
Scheduling GDAL/OGR Jobs</a></li>
<li><a href="#tips-for-improving-performance"
id="toc-tips-for-improving-performance">Tips for Improving
Performance</a>
<ul>
<li><a href="#configuration-options"
id="toc-configuration-options">Configuration Options</a></li>
<li><a href="#multithreading"
id="toc-multithreading">Multithreading</a></li>
</ul></li>
<li><a href="#supplement" id="toc-supplement">Supplement</a>
<ul>
<li><a href="#check-supported-formats-and-capabilities"
id="toc-check-supported-formats-and-capabilities">Check Supported
Formats and Capabilities</a></li>
<li><a href="#extracting-image-metadata-and-statistics"
id="toc-extracting-image-metadata-and-statistics">Extracting Image
Metadata and Statistics</a></li>
<li><a href="#validating-cogs" id="toc-validating-cogs">Validating
COGs</a></li>
<li><a href="#creating-contours" id="toc-creating-contours">Creating
Contours</a></li>
<li><a href="#creating-colorized-imagery"
id="toc-creating-colorized-imagery">Creating Colorized Imagery</a></li>
<li><a href="#creating-colorized-hillshade"
id="toc-creating-colorized-hillshade">Creating Colorized
Hillshade</a></li>
<li><a href="#removing-jpeg-compression-artifacts"
id="toc-removing-jpeg-compression-artifacts">Removing JPEG Compression
Artifacts</a></li>
<li><a href="#splitting-a-mosaic-into-tiles"
id="toc-splitting-a-mosaic-into-tiles">Splitting a Mosaic into
Tiles</a></li>
<li><a href="#extracting-projection-information-from-a-raster"
id="toc-extracting-projection-information-from-a-raster">Extracting
Projection Information from a Raster</a></li>
<li><a href="#merging-files-with-different-resolutions"
id="toc-merging-files-with-different-resolutions">Merging Files with
Different Resolutions</a></li>
<li><a href="#calculate-pixel-wise-statistics-over-multiple-rasters"
id="toc-calculate-pixel-wise-statistics-over-multiple-rasters">Calculate
Pixel-Wise Statistics over Multiple Rasters</a></li>
<li><a href="#extracting-values-from-a-raster"
id="toc-extracting-values-from-a-raster">Extracting Values from a
Raster</a></li>
<li><a href="#masking-values-using-a-binary-raster"
id="toc-masking-values-using-a-binary-raster">Masking Values using a
Binary Raster</a></li>
<li><a href="#raster-to-vector-conversion"
id="toc-raster-to-vector-conversion">Raster to Vector
Conversion</a></li>
<li><a href="#viewshed-analysis" id="toc-viewshed-analysis">Viewshed
Analysis</a></li>
<li><a href="#working-with-kml-files"
id="toc-working-with-kml-files">Working with KML Files</a></li>
<li><a href="#group-statistics" id="toc-group-statistics">Group
Statistics</a></li>
<li><a href="#using-virtual-layers" id="toc-using-virtual-layers">Using
Virtual Layers</a></li>
</ul></li>
<li><a href="#resources" id="toc-resources">Resources</a></li>
<li><a href="#data-credits" id="toc-data-credits">Data Credits</a></li>
<li><a href="#license" id="toc-license">License</a></li>
</ul>
</div>

<div style="page-break-after: always;"></div>
<hr />
<p><img src="images/spatial_thoughts_logo.png" width="250pt" style="display: block; margin: auto;" /></p>
<hr />
<div style="page-break-after: always;"></div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p><a href="https://gdal.org/">GDAL</a> is an open-source library for
raster and vector geospatial data formats. The library comes with a vast
collection of utility programs that can perform many geoprocessing
tasks. This class introduces GDAL and OGR utilities with example
workflows for processing raster and vector data. The class also shows
how to use these utility programs to build Spatial ETL pipelines and do
batch processing.</p>
<p><a
href="https://www.youtube.com/watch?v=72WVyc8Jtz4&amp;list=PLppGmFLhQ1HLVaHVf4TsnJ4HXZBSfxLOK&amp;index=2"
target="_blank"><img
src="https://img.youtube.com/vi/72WVyc8Jtz4/mqdefault.jpg"
alt="Watch the video" /></a></p>
<p><a
href="https://www.youtube.com/watch?v=72WVyc8Jtz4&amp;list=PLppGmFLhQ1HLVaHVf4TsnJ4HXZBSfxLOK&amp;index=2"
target="_blank">Watch the Video ↗</a></p>
<p><a
href="https://docs.google.com/presentation/d/1JvGjb5eNM9F--zfyTFAeAk0R5UG6weFpOUVDVkJSnho/edit?usp=sharing"
target="_blank">Access the Presentation ↗</a></p>
</div>
<div id="setting-up-the-environment" class="section level1">
<h1>Setting up the Environment</h1>
<p>This course requires installing the GDAL package. Along with GDAL, we
highly recommend installing QGIS to view the result of the command-line
operations. You will find installation instructions for both the
software below.</p>
<div id="install-gdal" class="section level2">
<h2>Install GDAL</h2>
<p>The preferred method for installing the GDAL Tools is via Anaconda.
Follow these steps to install Anaconda and the GDAL library.</p>
<p><a href="https://www.anaconda.com/products/individual">Download the
Anaconda Installer</a> for Python 3.7 (or a higher version) for your
operating system. Once downloaded, double click the installer and
install it into the default suggested directory.</p>
<p><em>Note: If your username has spaces, or non-English characters, it
causes problems. In that case, you can install it to a path such as
<code>C:\anaconda</code>.</em></p>
<p><img src="images/gdal/conda.png" width="75%" style="display: block; margin: auto;" /></p>
<div id="windows" class="section level3">
<h3>Windows</h3>
<p>Once Anaconda installed, search for <em>Anaconda Prompt</em> in the
Start Menu and launch a new window.</p>
<ol style="list-style-type: decimal">
<li>Create a new environment named <code>gdal</code>. When prompted to
confirm, type <code>y</code> and press <em>Enter</em>.</li>
</ol>
<pre><code>conda create --name gdal</code></pre>
<blockquote>
<p>Note: You can select <em>Right Click → Paste</em> to paste commands
in Anaconda Prompt.</p>
</blockquote>
<p><img src="images/gdal/condawin1.png" width="75%" style="display: block; margin: auto;" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Activate the environment and install the <code>gdal</code> package.
When prompted to confirm, type <code>y</code> and press
<em>Enter</em>.</li>
</ol>
<pre><code>conda activate gdal
conda install -c conda-forge gdal</code></pre>
<p><img src="images/gdal/condawin2.png" width="75%" style="display: block; margin: auto;" /></p>
<ol start="3" style="list-style-type: decimal">
<li>Once the installation finishes, verify if you are able to run the
GDAL tools. Type the following command and check if a version number is
printed.</li>
</ol>
<pre><code>gdalinfo --version</code></pre>
<blockquote>
<p>The version number displayed for you may be slightly different. As
long as you do not get a <code>command not found</code> error, you
should be set for the class.</p>
</blockquote>
<p><img src="images/gdal/condawin3.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="maclinux" class="section level3">
<h3>Mac/Linux</h3>
<p>Once Anaconda is installed, launch a <em>Terminal</em> window.</p>
<ol style="list-style-type: decimal">
<li>Create a new environment named <code>gdal</code>. When prompted to
confirm, type <code>y</code> and press <em>Enter</em>.</li>
</ol>
<pre><code>conda create --name gdal</code></pre>
<p><img src="images/gdal/condamac1.png" width="75%" style="display: block; margin: auto;" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Activate the environment and install the <code>gdal</code> package.
When prompted to confirm, type <code>y</code> and press
<em>Enter</em>.</li>
</ol>
<pre><code>conda activate gdal
conda install -c conda-forge gdal</code></pre>
<p><img src="images/gdal/condamac2.png" width="75%" style="display: block; margin: auto;" /></p>
<ol start="3" style="list-style-type: decimal">
<li>Once the installation finishes, verify if you are able to run the
GDAL tools. Type the following command and check if a version number is
printed.</li>
</ol>
<pre><code>gdalinfo --version</code></pre>
<blockquote>
<p>The version number displayed for you may be slightly different. As
long as you do not get a <code>command not found</code> error, you
should be set for the class.</p>
</blockquote>
<p><img src="images/gdal/condamac3.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="google-colab-notebook-optional" class="section level3">
<h3>Google Colab Notebook [Optional]</h3>
<p>We also provide a Google Colab Notebook for the course that allows
you to run all the workflows in the cloud without the need to install
any packages or download any datasets. You may use this as an
alternative environment if you cannot install the software on your
machine due to security restrictions.</p>
<p><a
href="https://colab.research.google.com/github/spatialthoughts/courses/blob/master/code/gdal/mastering_gdal_tools.ipynb"
target="_blank"><img
src="https://colab.research.google.com/assets/colab-badge.svg"
alt="Open In Colab" /></a></p>
</div>
</div>
<div id="install-qgis" class="section level2">
<h2>Install QGIS</h2>
<p>This course uses QGIS LTR version for visualization of results. It is
not mandatory to install QGIS, but highly recommended.</p>
<p>Please review <a href="install-qgis-ltr.html">QGIS-LTR Installation
Guide</a> for step-by-step instructions.</p>
</div>
</div>
<div id="download-the-data-package" class="section level1">
<h1>Download the Data Package</h1>
<p>The code examples in this class use a variety of datasets. All the
required datasets are supplied to you in the <code>gdal_tools.zip</code>
file. Unzip this file to the <code>Downloads</code> directory. All
commands below assume the data is available in the
<code>&lt;home folder&gt;/Downloads/gdal_tools/</code> directory.</p>
<p>Download <a
href="https://drive.google.com/uc?export=download&amp;id=1JzRmxStcCiyxlLRNZCC5nkVH12Hmr1ZE">gdal-tools.zip</a>.</p>
<blockquote>
<p>Note: Certification and Support are only available for participants
in our paid instructor-led classes.</p>
</blockquote>
</div>
<div id="get-the-course-videos" class="section level1">
<h1>Get the Course Videos</h1>
<p>The course is accompanied by a set of videos covering the all the
modules. These videos are recorded from our live instructor-led classes
and are edited to make them easier to consume for self-study. We have 2
versions of the videos:</p>
<div id="youtube" class="section level2">
<h2>YouTube</h2>
<p>We have created a YouTube Playlist with separate videos for each
section and exercise to enable effective online-learning. <a
href="https://www.youtube.com/playlist?list=PLppGmFLhQ1HLVaHVf4TsnJ4HXZBSfxLOK"
target="_blank">Access the YouTube Playlist ↗</a></p>
</div>
<div id="vimeo" class="section level2">
<h2>Vimeo</h2>
<p>We are also making combined full-length video for each module
available on Vimeo. These videos can be downloaded for offline learning.
<a href="https://vimeo.com/showcase/11112911" target="_blank">Access the
Vimeo Playlist ↗</a></p>
</div>
</div>
<div id="getting-familiar-with-the-command-prompt"
class="section level1">
<h1>Getting Familiar with the Command Prompt</h1>
<p>All the commands in the exercises below are expected to be run from
the <em>Anaconda Prompt</em> on Windows or a <em>Terminal</em> on
Mac/Linux. We will now cover basic terminal commands that will help you
get comfortable with the environment</p>
<div id="windows-1" class="section level3">
<h3>Windows</h3>
<table>
<colgroup>
<col width="23%" />
<col width="48%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Command</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>cd</code></td>
<td align="left">Change directory</td>
<td align="left"><code>cd Downloads\gdal-tools</code></td>
</tr>
<tr class="even">
<td align="left"><code>cd ..</code></td>
<td align="left">Change to the parent directory</td>
<td align="left"><code>cd ..</code></td>
</tr>
<tr class="odd">
<td align="left"><code>dir</code></td>
<td align="left">List files in the current directory</td>
<td align="left"><code>dir</code></td>
</tr>
<tr class="even">
<td align="left"><code>del</code></td>
<td align="left">Delete a file</td>
<td align="left"><code>del test.txt</code></td>
</tr>
<tr class="odd">
<td align="left"><code>rmdir</code></td>
<td align="left">Delete a directory</td>
<td align="left"><code>rmdir /s test</code></td>
</tr>
<tr class="even">
<td align="left"><code>mkdir</code></td>
<td align="left">Create a directory</td>
<td align="left"><code>mkdir test</code></td>
</tr>
<tr class="odd">
<td align="left"><code>type</code></td>
<td align="left">Print the contents of a file</td>
<td align="left"><code>type test.txt</code></td>
</tr>
<tr class="even">
<td align="left"><code>&gt; output.txt</code></td>
<td align="left">Redirect the output to a file</td>
<td align="left"><code>dir /b  &gt; test.txt</code></td>
</tr>
<tr class="odd">
<td align="left"><code>cls</code></td>
<td align="left">Clear screen</td>
<td align="left"><code>cls</code></td>
</tr>
</tbody>
</table>
</div>
<div id="maclinux-1" class="section level3">
<h3>Mac/Linux</h3>
<table>
<colgroup>
<col width="23%" />
<col width="48%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Command</strong></th>
<th align="left"><strong>Description</strong></th>
<th align="left"><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>cd</code></td>
<td align="left">Change directory</td>
<td align="left"><code>cd Downloads/gdal-tools</code></td>
</tr>
<tr class="even">
<td align="left"><code>cd ..</code></td>
<td align="left">Change to the parent directory</td>
<td align="left"><code>cd ..</code></td>
</tr>
<tr class="odd">
<td align="left"><code>ls</code></td>
<td align="left">List files in the current directory</td>
<td align="left"><code>ls</code></td>
</tr>
<tr class="even">
<td align="left"><code>rm</code></td>
<td align="left">Delete a file</td>
<td align="left"><code>rm test.txt</code></td>
</tr>
<tr class="odd">
<td align="left"><code>rm -R</code></td>
<td align="left">Delete a directory</td>
<td align="left"><code>rm -R test</code></td>
</tr>
<tr class="even">
<td align="left"><code>mkdir</code></td>
<td align="left">Create a directory</td>
<td align="left"><code>mkdir test</code></td>
</tr>
<tr class="odd">
<td align="left"><code>cat</code></td>
<td align="left">Print the contents of a file</td>
<td align="left"><code>cat test.txt</code></td>
</tr>
<tr class="even">
<td align="left"><code>&gt; output.txt</code></td>
<td align="left">Redirect the output to a file</td>
<td align="left"><code>ls &gt; test.txt</code></td>
</tr>
<tr class="odd">
<td align="left"><code>clear</code></td>
<td align="left">Clear screen</td>
<td align="left"><code>clear</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="gdal-tools" class="section level1">
<h1>1. GDAL Tools</h1>
<p><a
href="https://www.youtube.com/watch?v=QMJR6JCogDk&amp;list=PLppGmFLhQ1HLVaHVf4TsnJ4HXZBSfxLOK&amp;index=6"
target="_blank"><img
src="https://img.youtube.com/vi/QMJR6JCogDk/mqdefault.jpg"
alt="Start Module Videos" /></a></p>
<p><a
href="https://www.youtube.com/watch?v=QMJR6JCogDk&amp;list=PLppGmFLhQ1HLVaHVf4TsnJ4HXZBSfxLOK&amp;index=6"
target="_blank">Start Module Videos ↗</a></p>
<div id="basic-raster-processing" class="section level2">
<h2>1.1 Basic Raster Processing</h2>
<p>We will start learning the basic GDAL commands by processing
elevation rasters from SRTM. In the <em>Command Prompt</em> window, use
the <code>cd</code> command to change to the <code>srtm</code> directory
which 4 individual SRTM tiles around the Mt. Everest region.</p>
<pre><code>cd srtm</code></pre>
<p>Use the <code>gdalinfo</code> command to check the information about
a single image.</p>
<pre><code>gdalinfo N28E086.hgt</code></pre>
<p><img src="images/gdal/gdalinfo1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>A useful parameter is <code>-stats</code> which computes and displays
image statistics. Run it on the raster to get some statistics of pixel
values in the image.</p>
<pre><code>gdalinfo -stats N28E086.hgt</code></pre>
<p><img src="images/gdal/gdalinfo2.png" width="75%" style="display: block; margin: auto;" /></p>
<div id="merging-tiles" class="section level3">
<h3>1.1.1 Merging Tiles</h3>
<p>We will now merge the 4 neighboring SRTM tiles into 1 raster so we
can work with them together. GDAL provides a useful format called <a
href="https://gdal.org/drivers/raster/vrt.html">Virtual Raster</a> that
allows us to create a <em>Virtual</em> file with <code>.vrt</code>
extension that is a pointer to multiple source files. A
<code>.vrt</code> file is just a text file, so it doesn’t consume any
disk space but allows us to run any GDAL command as if it was a raster
file.</p>
<p>First we need to create a text file containing all the files we want
to merge. We can use the <code>dir</code> command on Command prompt to
list the files matching the pattern <code>*.hgt</code> and redirect the
output to a file. Here the <code>/b</code> option runs the command in
the <em>Bare</em> mode which excludes all info except file names.</p>
<p><strong>Windows</strong></p>
<pre><code>dir /b *.hgt &gt; filelist.txt</code></pre>
<p>For Mac/Linux systems, the same can be achieved using the
<code>ls</code> command.</p>
<p><strong>Mac/Linux</strong></p>
<pre><code>ls *.hgt &gt; filelist.txt</code></pre>
<p>Once the command finishes, verify that the <code>filelist.txt</code>
has the names of the source tiles.</p>
<p><img src="images/gdal/merging1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>We can now use the <code>gdalbuildvrt</code> program to create a
virtual raster from the source files in the
<code>filelist.txt</code>.</p>
<pre><code>gdalbuildvrt -input_file_list filelist.txt merged.vrt</code></pre>
<p><img src="images/gdal/merging2.png" width="100%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Note: We could have done this operation in a single step using the
command <code>gdalbuildvrt merged.vrt *.hgt</code>. However, some
versions of GDAL on Windows do not expand the <code>*</code> wildcard
correctly and the command results in an error. It is recommended to use
a file list instead of wildcards with GDAL commands on Windows to avoid
unexpected results.[<a
href="https://github.com/OSGeo/gdal/issues/1749">reference</a>]</p>
</blockquote>
</div>
<div id="exercise-1" class="section level3">
<h3>Exercise 1</h3>
<p>Can you find what is the highest elevation value in the merged
raster? Since these rasters are around the Mt.Everest region, the
<em>MAXIMUM</em> value will be the elevation of the summit.</p>
<p><img src="images/gdal/exercise1.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="converting-formats" class="section level3">
<h3>1.1.2 Converting Formats</h3>
<p>Let’s convert the <em>Virtual Raster</em> to a GeoTIFF file.
<code>gdal_translate</code> program allows us to convert between any of
the hundreds of data formats supported by GDAL. The format is recognized
from the file extension. Alternatively, you can also specify it using
the <code>-of</code> option with the <a
href="https://gdal.org/drivers/raster/index.html">short name of the
format</a> such a <strong>GTiff</strong>.</p>
<pre><code>gdal_translate -of GTiff merged.vrt merged.tif</code></pre>
<p><img src="images/gdal/compression1.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="compressing-output" class="section level3">
<h3>1.1.3 Compressing Output</h3>
<p>The default output GeoTIFF file is uncompressed - meaning each
pixel’s value is stored on the disk without any further processing. For
large rasters, this can consume a lot of disk space. A smart approach is
to use a lossless compression algorithm to reduce the size of the raster
while maintaining full fidelity of the original data. GDAL supports many
compression algorithms out-of-the-box and can be specified with GDAL
commands using the <code>-co</code> option. The most popular loss-less
compression algorithms are <strong>DEFLATE</strong>,
<strong>LZW</strong> and <strong>PACKBITS</strong>. We can try the
<code>DEFLATE</code> algorithm on our dataset.</p>
<pre><code>gdal_translate -of GTiff merged.vrt merged.tif -co COMPRESS=DEFLATE</code></pre>
<p><img src="images/gdal/compression2.png" width="75%" style="display: block; margin: auto;" /></p>
<p>The uncompressed file size was <strong>100+ MB</strong>. After
applying the <em>DEFLATE</em> compression, the file size was reduced to
<strong>75MB</strong>. We can further reduce the file size by specifying
additional options. The <code>PREDICTOR</code> option helps compress
data better when the neighboring values are correlated. For elevation
data, this is definitely the case. The <code>TILED</code> option will
compress the data in blocks rather than line-by-line.</p>
<blockquote>
<p>Note: You can split long commands into multiple lines using the
line-continuation character. Windows shell uses <code>^</code> as the
line-continuation, while Mac/Linux shells use <code>\</code> as the line
continuation.</p>
</blockquote>
<p><strong>Windows</strong></p>
<pre><code>gdal_translate -of GTiff merged.vrt merged.tif ^
  -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_translate -of GTiff merged.vrt merged.tif \
  -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2</code></pre>
<p><img src="images/gdal/compression3.png" width="75%" style="display: block; margin: auto;" /></p>
<p>The resulting file now comes out much smaller at
<strong>39MB</strong>. Check this article <a
href="https://kokoalberti.com/articles/geotiff-compression-optimization-guide/">GeoTIFF
compression and optimization with GDAL</a> to learn more about various
options and compression algorithms.</p>
</div>
<div id="setting-nodata-values" class="section level3">
<h3>1.1.4 Setting NoData Values</h3>
<p>The output from <code>gdalinfo</code> program shows that the original
data has a <em>NoData</em> Value set to <code>-32768</code>. We can set
a new <em>NoData</em> value. The <code>-a_nodata</code> option allows us
to specify a new value.</p>
<p><strong>Windows</strong></p>
<pre><code>gdal_translate -of GTiff merged.vrt merged.tif ^
  -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2 -a_nodata -9999</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_translate -of GTiff merged.vrt merged.tif \
  -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2 -a_nodata -9999</code></pre>
<p>After running the command, you can verify the results using the
<code>gdalinfo</code> command.</p>
</div>
<div id="writing-cloud-optimized-geotiff-cog" class="section level3">
<h3>1.1.5 Writing Cloud-Optimized GeoTIFF (COG)</h3>
<p>A new format called <a href="https://www.cogeo.org/">Cloud-Optimized
GeoTIFF (COG)</a> is making access to such a vast amount of imagery
easier to access and analyze. A <em>Cloud-optimized</em> GeoTIFF is
behaving just like a regular GeoTIFF imagery, but instead of downloading
the entire image locally, you can access <em>portions</em> of imagery
hosted on a cloud server streamed to clients like QGIS. This makes it
very efficient to access this data and even analyze it - without
downloading large files. GDAL makes it very easy to create COG files by
specifying the <code>-of COG</code> option. Specifying the
<code>-co NUM_THREADS=ALL_CPUS</code> helps speed up the creation
process by using all available CPUs for compression and creating
internal overviews.</p>
<p>The <a href="https://gdal.org/drivers/raster/cog.html">GDAL COG
Driver</a> has the following creation options <code>-co</code> enabled
by default.</p>
<ul>
<li>Has internal tiling (i.e. <code>-co TILED=YES</code>)</li>
<li>LZW Compression (i.e. <code>-co COMPRESS=LZW</code>)</li>
<li>Automatic Selection of Predictor
(i.e. <code>-co PREDICTOR=YES</code> chooses appropriate predictor for
data type)</li>
</ul>
<p><strong>Windows</strong></p>
<pre><code>gdal_translate -of COG merged.vrt merged_cog.tif ^
  -co COMPRESS=DEFLATE -co PREDICTOR=YES -co NUM_THREADS=ALL_CPUS ^
  -a_nodata -9999</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_translate -of COG merged.vrt merged_cog.tif \
  -co COMPRESS=DEFLATE -co PREDICTOR=YES -co NUM_THREADS=ALL_CPUS \
  -a_nodata -9999</code></pre>
</div>
</div>
<div id="processing-elevation-data" class="section level2">
<h2>1.2 Processing Elevation Data</h2>
<p>GDAL comes with the <code>gdaldem</code> utility that provides a
suite of tools for visualizing and analyzing Digital Elevation Models
(DEM). The tool supports the following modes</p>
<ul>
<li>Hillshade</li>
<li>Slope</li>
<li>Aspect</li>
<li>Color-relief</li>
<li>Terrain Ruggedness Index (TRI)</li>
<li>Topographic Position Index (TPI)</li>
<li>Roughness</li>
</ul>
<p>Am important point to note is that the x, y and z units of the DEM
should be of same unit. If you are using data in a Geographic CRS (like
EPSG:4326) and the height units are in meters, you must specify a scale
value using <code>-s</code> option.</p>
<div id="creating-hillshade" class="section level3">
<h3>1.2.1 Creating Hillshade</h3>
<p>Let’s create a hillshade map from the merged SRTM dataset. The
<code>hillshade</code> mode creates an 8-bit raster with a nice shaded
relief effect. This dataset has X and Y units in degrees and Z units in
meters. So we specify <code>111120</code> as the scale value.</p>
<pre><code>gdaldem hillshade merged.tif hillshade.tif -s 111120</code></pre>
<p><code>gdaldem</code> supports multiple hillshading algorithms. Apart
from the default, it currently includes the following algorithms.</p>
<ul>
<li>Combined shading (<code>-combined</code>): A combination of slope
and oblique shading.</li>
<li>Multidirectional shading (<code>-multidirectional</code>): A
combination of hillshading illuminated from 225 deg, 270 deg, 315 deg,
and 360 deg azimuth.</li>
</ul>
<p>Let’s create a hillshade map with the <code>-multidirectional</code>
option.</p>
<pre><code>gdaldem hillshade merged.tif hillshade_combined.tif -s 111120 -multidirectional</code></pre>
<p><img src="images/gdal/hillshade.png" width="100%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Creating hillshade that is representative of a terrain is more of an
‘art’ than science. The best hand-drawn relief shading is still done
manually by cartographers. Recent advances in Deep Learning have shown
promise to reproduce the state-of-the-art relief shading using automated
techniques. Learn more about <a
href="https://arxiv.org/pdf/2010.01256.pdf" target="_blank">Cartographic
Relief Shading with Neural Networks</a> and the accompanying software <a
href="https://eduard.earth/" target="_blank">Eduard</a>.</p>
</blockquote>
</div>
<div id="creating-color-relief" class="section level3">
<h3>1.2.2 Creating Color Relief</h3>
<p>A color relief map is an elevation map where different ranges of
elevations are colored differently. The <code>color-relief</code> mode
can create a color relief map with the colors and elevation ranges
supplied in a text file.</p>
<p>We need to supply the colormap using a text file. Create a new file
called <code>colormap.txt</code> with the following content and save it
in the same directory as <code>merged.tif</code>. The format of the text
file is <code>elevation, red, green, blue</code> values.</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="ex">1000,101,146,82</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="ex">1500,190,202,130</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="ex">2000,241,225,145</span></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a><span class="ex">2500,244,200,126</span></span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a><span class="ex">3000,197,147,117</span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a><span class="ex">4000,204,169,170</span></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a><span class="ex">5000,251,238,253</span></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a><span class="ex">6000,255,255,255</span></span></code></pre></div>
<p>We can supply this file to create a colorized elevation map.</p>
<pre><code>gdaldem color-relief merged.tif colormap.txt colorized.tif</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/colorized.png" alt="Color Relief" width="75%" />
<p class="caption">
Color Relief
</p>
</div>
</div>
<div id="exercise-2" class="section level3">
<h3>Exercise 2</h3>
<p>Save the color relief in the PNG format.</p>
</div>
</div>
<div id="processing-aerial-imagery" class="section level2">
<h2>1.3 Processing Aerial Imagery</h2>
<p>Use the <code>cd</code> command to change to the <code>naip</code>
directory which contains individual aerial imagery tiles in the
<strong>JPEG2000</strong> format.</p>
<pre><code>cd naip</code></pre>
<div id="create-a-preview-image-from-source-tiles"
class="section level3">
<h3>1.3.1 Create a preview image from source tiles</h3>
<p>The source imagery is heavily compressed and covers a large region.
Instead of loading the full resolution tiles in a viewer, it is a good
practice to create a preview mosaic that can help us assess the coverage
and quality of the data.</p>
<p>We first create a <em>Virtual Raster</em> mosaic from all the
<code>.jp2</code> tiles. We can create a text file containing all the
files we want to merge.</p>
<p><strong>Windows</strong></p>
<pre><code>dir /b *.jp2 &gt; filelist.txt</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ls *.jp2 &gt; filelist.txt</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/aoi_textfile.png" alt="Text File with the List of Images" width="75%" />
<p class="caption">
Text File with the List of Images
</p>
</div>
<p>We are working with Photometric RGB tiles and want to apply JPEG
compression on the result. To avoid JPEG artifact and maintain nodata
values, it is a good practice to add an Alpha band which will contain
the mask containing all valid pixels. We use the <code>-addalpha</code>
option to create an alpha band.</p>
<pre><code>gdalbuildvrt -addalpha -input_file_list filelist.txt naip.vrt</code></pre>
<p>We can use the <code>-outsize</code> option and specify a percentage
to generate a smaller size preview. The below command generates a 2%
preview image in JPEG format. Since we have a 4-band image, we specify
which bands to be used for generating the JPG image using the
<code>-b</code> option.</p>
<pre><code>gdal_translate -b 1 -b 2 -b 3 -of JPEG -outsize 2% 2% naip.vrt naip_preview.jpg </code></pre>
<p><img src="images/gdal/naip_preview.jpg" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="create-a-tile-index" class="section level3">
<h3>1.3.2 Create a Tile Index</h3>
<p>When working with large amounts of imagery tiles, it is useful to
generate a tile index. A tile index layer is a polygon layer with the
bounding box of each tile. An index layer allows us to check the
coverage of the source data and locate specific tiles. It is a simple
but effective way to catalog raster data from a hard drive or from a
folder on your computer.</p>
<p><code>gdaltindex</code> program creates a tile index from a list of
input files. Here we can use the <code>--optfile</code> option to supply
the list of files via a file.</p>
<pre><code>gdaltindex -write_absolute_path index.shp --optfile filelist.txt</code></pre>
</div>
<div id="mosaic-and-clip-to-aoi" class="section level3">
<h3>1.3.3 Mosaic and clip to AOI</h3>
<p>Let’s say we want to mosaic all the source tiles into a single image.
We also want to clip the mosaic to a given AOI.</p>
<p><img src="images/gdal/aoiselection.png" width="75%" style="display: block; margin: auto;" /></p>
<p>We can use the <code>gdalwarp</code> utility to clip the raster using
the <code>-cutline</code> option.</p>
<pre><code>gdalwarp -cutline aoi.shp  -crop_to_cutline naip.vrt aoi_cut.tif -co COMPRESS=DEFLATE -co TILED=YES</code></pre>
<p>We can also add JPEG compression to the output file to reduce the
file size. Refer to the post <a
href="https://blog.cleverelephant.ca/2015/02/geotiff-compression-for-dummies.html">GeoTiff
Compression for Dummies</a> by Paul Ramsey that gives more insights into
compression imagery. Note that JPEG is a lossy compression method and
can cause edge artifacts for image mosaics. To prevent this, we specify
the <code>--config GDAL_TIFF_INTERNAL_MASK YES</code> option that uses
the mask from the alpha band.</p>
<p><strong>Windows</strong></p>
<pre><code>gdal_translate aoi_cut.tif aoi.tif ^
  -co COMPRESS=JPEG -co TILED=YES -co PHOTOMETRIC=YCBCR -co JPEG_QUALITY=75 ^
  -b 1 -b 2 -b 3 -mask 4 --config GDAL_TIFF_INTERNAL_MASK YES</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_translate aoi_cut.tif aoi.tif \
  -co COMPRESS=JPEG -co TILED=YES -co PHOTOMETRIC=YCBCR -co JPEG_QUALITY=75 \
  -b 1 -b 2 -b 3 -mask 4 --config GDAL_TIFF_INTERNAL_MASK YES</code></pre>
<p><img src="images/gdal/mosaic.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="creating-overviews" class="section level3">
<h3>1.3.4 Creating Overviews</h3>
<p>If you try loading the resulting raster into a viewer, you will
notice that it takes a lot of time for it to render. Zoom/Pan operations
are quite slow as well. This is because the viewer is rendering all the
pixels at native resolution. Since this is a very high-resolution
dataset, it requires processing a lot of pixels, even if you are zoomed
out. A common solution to this problem is to create <em>Pyramid
Tiles</em> or <em>Overviews</em>. This process creates low-resolution
versions of the image by averaging pixel values from higher resolution
pixels. If the pyramid tiles are present, imagery viewers can use it to
speed up the rendering process. GDAL provides the utility
<code>gdaladdo</code> to create overview tiles. GeoTIFF format supports
storing the overviews within the file itself. For other formats, the
program generates external overviews in the <code>.ovr</code>
format.</p>
<p>You can run the <code>gdaladdo</code>
(<strong>GDAL</strong>-<strong>Add</strong>-<strong>O</strong>verview)
command with default options to create internal overviews. Once the
overviews are created, try opening the <code>aoi.tif</code> in QGIS. You
will see that it renders much faster and zoom/pan operations are very
smooth.</p>
<pre><code>gdaladdo aoi.tif</code></pre>
<p>The default overviews use the nearest neighbor resampling. We can
pick any resampling method from the many available algorithms. We can
try the bilinear interpolation using the <code>-r bilinear</code>
option. Since the source imagery is JPEG compressed, we will compress
the overviews with the same compression.</p>
<pre><code>gdaladdo -r bilinear --config COMPRESS_OVERVIEW JPEG aoi.tif</code></pre>
</div>
</div>
<div id="processing-satellite-imagery" class="section level2">
<h2>1.4 Processing Satellite Imagery</h2>
<p>This section shows how to use the satellite data from Landsat-8 and
create various derived products. Use the <code>cd</code> command to
switch to the <code>landsat8</code> directory which contains Landsat-8
imagery. This directory has 5 individual GeoTIFF files for 5 different
bands from a single landsat-8 scene.</p>
<table>
<thead>
<tr class="header">
<th align="left"><strong>Band Number</strong></th>
<th align="left"><strong>Band Name</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">B2</td>
<td align="left">Blue</td>
</tr>
<tr class="even">
<td align="left">B3</td>
<td align="left">Green</td>
</tr>
<tr class="odd">
<td align="left">B4</td>
<td align="left">Red</td>
</tr>
<tr class="even">
<td align="left">B5</td>
<td align="left">Near Infrared</td>
</tr>
<tr class="odd">
<td align="left">B8</td>
<td align="left">Panchromatic</td>
</tr>
</tbody>
</table>
<pre><code>cd landsat8</code></pre>
<div id="merging-individual-bands-into-rgb-composite"
class="section level3">
<h3>1.4.1 Merging individual bands into RGB composite</h3>
<p>Let’s create an RGB composite image by combining three 3 different
bands - Red, Green and Blue - into a single image. Here we must use the
<code>-separate</code> option which tells the command to place each
image in a separate band.</p>
<blockquote>
<p>Note: GDAL tools also have a <code>gdal_merge.py</code> script that
can also merge rasters into an image. But this script loads all rasters
into memory before merging them. This can lead to excessive RAM usage
and out of memory errors when working with large files.
<code>gdal_merge.py</code> can also be slower than using
<code>gdal_translate</code> - when you have large files. So a preferred
approach for merging large files would be using the virtual raster as
shown here.</p>
</blockquote>
<p><strong>Windows</strong></p>
<pre><code>gdalbuildvrt -o rgb.vrt -separate ^
  RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.tif ^
  RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B3.tif ^
  RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B2.tif</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdalbuildvrt -o rgb.vrt -separate \
  RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.tif \
  RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B3.tif \
  RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B2.tif</code></pre>
<p>Then use <code>gdal_translate</code> to merge them.</p>
<pre><code>gdal_translate rgb.vrt rgb.tif -co PHOTOMETRIC=RGB -co COMPRESS=DEFLATE </code></pre>
<p>Once the command finishes, you can view the result in QGIS.</p>
<p><img src="images/gdal/rgb.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="apply-histogram-stretch-and-color-correction"
class="section level3">
<h3>1.4.2 Apply Histogram Stretch and Color Correction</h3>
<p>The resulting composite appears quite dark and has low-contrast. QGIS
applies a default contrast stretch based on the minimum and maximum
values in the image. Due to the presence of clouds and cloud-shadows -
there are outlier pixels that make the default contrast stretch not
optimal.</p>
<p>Here’s what the histogram of the RGB composite looks like.</p>
<p><img src="images/gdal/histogram.png" width="75%" style="display: block; margin: auto;" /></p>
<p>We can apply a histogram stretch to increase the contrast. This is
done using the <code>-scale</code> option. Since most of the pixels have
a value between 0 and 0.3, we can choose these are minimum and maximum
values and apply a contrast stretch to make them go from 0 to 255. The
resulting image will be an 8-bit color image where the input pixel
values are linearly scaled to the target value.</p>
<blockquote>
<p>Note: Scaling the image will alter the pixel values. The resulting
image is suitable for visualization, but they should never be used for
analysis. Scientific analysis should always use the un-scaled pixel
values.</p>
</blockquote>
<pre><code>gdal_translate -scale 0 0.3 0 255 -ot Byte rgb.tif rgb_stretch.tif</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/rgb_stretch_linear.png" alt="RGB Composite with Linear Stretch" width="75%" />
<p class="caption">
RGB Composite with Linear Stretch
</p>
</div>
<p>We can also apply a non-linear stretch. <code>gdal_translate</code>
has a <code>-exponent</code> option that scales the input values using
the following formula. Choosing an exponent value between 0 and 1 will
enhance low intensity values - resulting in a brighter image. <a
href="https://homepages.inf.ed.ac.uk/rbf/HIPR2/pixexp.htm">Learn
more</a></p>
<p>Let’s try exponent value of <strong>0.5</strong>. The result is a
much better looking output.</p>
<pre><code>gdal_translate -scale 0 0.3 0 255 -exponent 0.5 -ot Byte rgb.tif rgb_stretch.tif</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/rgb_stretch_exponent.png" alt="RGB Composite with Exponential Stretch" width="75%" />
<p class="caption">
RGB Composite with Exponential Stretch
</p>
</div>
</div>
<div id="raster-algebra" class="section level3">
<h3>1.4.3 Raster Algebra</h3>
<p>For raster algebra operations, GDAL provides a raster calculator
program <code>gdal_calc.py</code>. The input rasters are specified using
any letters from A-Z. These letters can be then referenced in the
expression. The expression is specified using the <code>--calc</code>
option and it supports NumPy syntax and <a
href="https://numpy.org/doc/stable/reference/routines.math.html#">functions</a>.</p>
<pre><code>gdalinfo -stats RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.tif</code></pre>
<p>It is important to set NoData value. As seen from the output above,
NoData is set to <strong>-999</strong>.</p>
<blockquote>
<p>Note that Windows users need to specify the full path to the GDAL
scripts and run it with the python command as shown below. Mac/Linux
users can just type the script name directly but if you get an error,
you can also specify the full path on Mac/Linux as
<code>python $CONDA_PREFIX/bin/gdal_merge.py</code></p>
</blockquote>
<p><strong>Windows</strong></p>
<pre><code>python %CONDA_PREFIX%\Scripts\gdal_calc.py ^
  -A RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B5.tif ^
  -B RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.tif ^
  --outfile ndvi.tif --calc=&quot;(A-B)/(A+B)&quot; --NoDataValue=-999</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_calc.py -A RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B5.tif \
  -B RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.tif \
  --outfile ndvi.tif --calc=&quot;(A-B)/(A+B)&quot; --NoDataValue=-999</code></pre>
<p><img src="images/gdal/ndvi.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="exercise-3" class="section level3">
<h3>Exercise 3</h3>
<p>Create an NRG Composite image with Near Infrared, Red and Green
bands. Apply a contrast stretch to the result and save it as a PNG
image.</p>
<div class="figure" style="text-align: center">
<img src="images/gdal/nrg_stretch.png" alt="NRG Composite" width="75%" />
<p class="caption">
NRG Composite
</p>
</div>
</div>
<div id="pan-sharpening" class="section level3">
<h3>1.4.4 Pan Sharpening</h3>
<p>Most satellite and airborne sensors capture images in the
<em>Pan-chromatic</em> band along with other spectral bands. The
<em>Red</em>, <em>Green</em>, and <em>Blue</em> bands capture signals in
the <em>Red</em>, <em>Green</em>, and <em>Blue</em> portions of the
electromagnetic spectrum respectively. But the <em>Pan</em>-band
captures the data across the entire range of wavelengths in the visible
spectrum. This allows the sensor to capture the data in a higher spatial
resolution than other bands which capture the signal from a subset of
this wavelength range.</p>
<p>Landsat-8 satellite produces images at a <strong>30m</strong> spatial
resolution in the <em>Red</em>, <em>Green</em>, <em>Blue</em> bands and
at a <strong>15m</strong> spatial resolution in the
<em>Panchromatic</em> band. We can use the higher spatial resolution of
the <em>Panchromatic</em> band to improve the resolution of the other
bands, resulting in a sharper image with more details. This process is
called <em>Pan-Sharpening</em>.</p>
<p>GDAL comes with a script <code>gdal_pansharpen.py</code> that
implements the <a
href="https://gdal.org/drivers/raster/vrt.html#gdal-vrttut-pansharpen">Brovey
algorithm</a> to compute the pansharpened output. In the example below
we fuse the 15m resolution panchromatic band (B8) with the RGB composite
created in the previous step.</p>
<p><strong>Windows</strong></p>
<pre><code>python %CONDA_PREFIX%\Scripts\gdal_pansharpen.py RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B8.tif ^
  rgb.tif pansharpened.tif -r bilinear -co COMPRESS=DEFLATE -co PHOTOMETRIC=RGB</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_pansharpen.py RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B8.tif \
  rgb.tif pansharpened.tif -r bilinear -co COMPRESS=DEFLATE -co PHOTOMETRIC=RGB</code></pre>
<p>We can apply the same contrast stretch as before and compare the
output. You will notice that the resulting composite is much sharper and
can resolve the details in the scene much better.</p>
<p><strong>Windows</strong></p>
<pre><code>gdal_translate -scale 0 0.3 0 255 -exponent 0.5 -ot Byte -a_nodata 0 ^
  pansharpened.tif pansharpened_stretch.tif</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_translate -scale 0 0.3 0 255 -exponent 0.5 -ot Byte -a_nodata 0 \
  pansharpened.tif pansharpened_stretch.tif</code></pre>
<p><img src="images/gdal/pansharpen_before.png" width="75%" style="display: block; margin: auto;" /></p>
<p><img src="images/gdal/pansharpen_after.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="processing-wms-layers" class="section level2">
<h2>1.5 Processing WMS Layers</h2>
<p>GDAL supports reading from a variety of web services, including <a
href="https://gdal.org/drivers/raster/wms.html">Web Map Services
(WMS)</a> layers.</p>
<div id="listing-wms-layers" class="section level3">
<h3>1.5.1 Listing WMS Layers</h3>
<p>NASA’s Socioeconomic Data and Applications Center (SEDAC) provides
many useful data layers though <a
href="https://sedac.ciesin.columbia.edu/maps/services">WMS Services</a>.
We can pick the URL for the appropriate service and list all available
layers using <code>gdalinfo</code>.</p>
<pre><code>gdalinfo &quot;WMS:https://sedac.ciesin.columbia.edu/geoserver/ows?version=1.3.0&quot;</code></pre>
<p><img src="images/gdal/wms1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We can get more information about a particular layer by specifying
the output from the command above. Let’s get more info about the <a
href="https://sedac.ciesin.columbia.edu/data/set/grand-v1-reservoirs-rev01">Global
Reservoir and Dam (GRanD), v1</a> layer.</p>
<pre><code>gdalinfo &quot;WMS:https://sedac.ciesin.columbia.edu/geoserver/ows?SERVICE=WMS&amp;VERSION=1.3.0&amp;REQUEST=GetMap&amp;LAYERS=grand-v1%3Agrand-v1-reservoirs-rev01&amp;CRS=CRS:84&amp;BBOX=-153.037,-45.881,176.825,70.398&quot;</code></pre>
</div>
<div id="creating-a-service-description-file" class="section level3">
<h3>1.5.2 Creating a Service Description File</h3>
<p>GDAL can also create a Service Description XML file from a WMS layer.
Many GIS programs, including QGIS recognize these XML files as valid
raster layers. This allows users to easily drag-and-drop them into their
favorite viewer to access a WMS service without any configuration.
<code>gdal_translate</code> can write the WMS XML files by specifying
<code>-of WMS</code> option.</p>
<pre><code>gdal_translate -of WMS &quot;WMS:https://sedac.ciesin.columbia.edu/geoserver/ows?SERVICE=WMS&amp;VERSION=1.3.0&amp;REQUEST=GetMap&amp;LAYERS=grand-v1%3Agrand-v1-reservoirs-rev01&amp;CRS=CRS:84&amp;BBOX=-153.037,-45.881,176.825,70.398&quot; reservoirs.xml</code></pre>
</div>
<div id="downloading-wms-layers" class="section level3">
<h3>1.5.3 Downloading WMS Layers</h3>
<p>Some applications require offline access to WMS layers. If you want
to use a WMS layer as a reference map for field-data collection, or use
the layer on a system with low-bandwidth, you can create a georeferenced
raster from a WMS layer. Depending on the server configuration, WMS
layers can serve data for resolutions exceeding their native resolution,
so one should explicitly specify the output resolution. We can use
<code>gdalwarp</code> with the <code>-tr</code> option to specify the
output resolution you need for the offline raster. In the example below,
we create a 0.1 degree resolution raster from the WMS layer.</p>
<pre><code>gdalwarp -tr 0.1 0.1 reservoirs.xml reservoirs.tif -co COMPRESS=DEFLATE -co TILED=YES</code></pre>
<p><img src="images/gdal/wms4.png" width="75%" style="display: block; margin: auto;" /></p>
<p>We can also extract a higher resolution extract for a specific region
by specifying the extent using the <code>-te</code> option.</p>
<pre><code>gdalwarp -tr 0.005 0.005 -te 68.106 6.762 97.412 37.078 reservoirs.xml reservoirs_india.tif -co COMPRESS=DEFLATE -co TILED=YES</code></pre>
<p><img src="images/gdal/wms5.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Learn more about offline WMS and comparison between different formats
in this article <a
href="https://www.opengis.ch/2020/06/09/offline-wms-benchmarking-raster-formats-for-qfield/">Offline
WMS – Benchmarking raster formats for QField</a> by OpenGIS.ch.</p>
</div>
<div id="exercise-4" class="section level3">
<h3>Exercise 4</h3>
<p>Instead of specifying the resolution in degrees, we want to download
the layer at a specific resolution in meters. We can re-project the
layer to a projected CRS and specify the output resolution in the units
of the target CRS.</p>
<p>Create a command that takes the <code>reservoirs.xml</code> file and
creates a GeoTiff file called
<code>reservoirs_india_reprojected.tif</code>for the India region at
500m resolution in the CRS <strong>WGS 84 / India NSF LCC
(EPSG:7755)</strong>.</p>
<p>You can use the hints below to construct your command.</p>
<ul>
<li>Specify the extent using <code>-te</code> option as
<code>68.106 6.762 97.412 37.078</code> in the
<code>xmin ymin xmax ymax</code> order.</li>
<li>The extent coordinates are in WGS84 Lat/Lon coordinates. So specify
the CRS of the extent coordinates using <code>-te_srs</code>.</li>
<li>Use the <code>-t_srs</code> option to specify the target CRS as
<code>EPSG:7755</code>.</li>
<li>Use the <code>-tr</code> option to specify the X and Y pixel
resolution.</li>
</ul>
</div>
</div>
<div id="georeferencing" class="section level2">
<h2>1.6 Georeferencing</h2>
<p>GDAL command-line utilities are extremely useful in batch
georeferencing tasks. We will learn 2 different techniques for
georeferencing/warping images.</p>
<div id="georeferencing-images-with-bounding-box-coordinates"
class="section level3">
<h3>1.6.1 Georeferencing Images with Bounding Box Coordinates</h3>
<p>Often you get images from web portals that are maps but lack
georeferencing information. Data from weather satellites, output from
simulations, exports from photo editing software etc. can contain images
that reference a fixed frame on the earth but are given in regular image
formats such as JPEG or PNG. If the bounding box coordinates and the CRS
used in creating these images are known, use <code>gdal_translate</code>
command to assign georeference information. The <code>-a_ullr</code>
option allows you to specify the bounding box coordinates using the
Upper-Left (UL) and Lower-Right (LR) coordinates.</p>
<p>Your data package contains the image file
<code>earth_at_night.jpg</code>. This is a beautifully rendered image of
the earth captured at night time. You will see that this is a plain JPEG
image without any georeference information.</p>
<pre><code>gdalinfo earth_at_night.jpg</code></pre>
<p>Since this is a global image, we know the corner coordinates. We can
assign the CRS <strong>EPSG:4326</strong> using the <code>-a_srs</code>
option and specify the bounding box coordinates in the following order
<code>&lt;ulx&gt; &lt;uly&gt; &lt;lrx&gt; &lt;lry&gt;</code>.</p>
<p><strong>Windows</strong></p>
<pre><code>gdal_translate -a_ullr -180 90 180 -90 -a_srs EPSG:4326 ^
  earth_at_night.jpg earth_at_night.tif ^
  -co COMPRESS=JPEG -co TILED=YES -co PHOTOMETRIC=RGB</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_translate -a_ullr -180 90 180 -90 -a_srs EPSG:4326 \
  earth_at_night.jpg earth_at_night.tif \
  -co COMPRESS=JPEG -co TILED=YES -co PHOTOMETRIC=RGB</code></pre>
<p>The resulting file <code>earth_at_night.tif</code> is a GeoTiff file
with the correct georeference information and can now be used in GIS
software.</p>
<pre><code>gdalinfo earth_at_night.tif</code></pre>
<p><img src="images/gdal/earth_at_night.png" width="341" style="display: block; margin: auto;" /></p>
</div>
<div id="georeferencing-with-gcps" class="section level3">
<h3>1.6.2 Georeferencing with GCPs</h3>
<p>Another option for georeferencing images it by using Ground Control
Points (GCPs) or Tie-Points. A GCP specifies the real-world coordinates
for a given pixel in the image. The GCPs can be obtained by reading the
map markings or locating landmarks from a georeferenced source. Given a
set of GCPs, <code>gdalwarp</code> can georeference the image using a
variety of transformation types.</p>
<p>Your data package contain an old scanned map called
<code>1870_southern_india.jpg</code>.</p>
<p><img src="images/gdal/scanned_map.png" width="388" style="display: block; margin: auto;" /></p>
<p>The map has graticule lines with latitude and longitude markings. To
obtain the GCPs, we can read the coordinate values at the grid
intersections and find the pixel’s image coordinates. You can use an
image viewer or the <em>Georeferencer</em> tool in QGIS to obtain GCPs
like below.</p>
<table>
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="32%" />
<col width="26%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>pixel (column)</strong></th>
<th align="left"><strong>line (row)</strong></th>
<th align="left"><strong>X (Longitude)</strong></th>
<th align="left"><strong>Y (Latitude)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">418</td>
<td align="left">893</td>
<td align="left">70</td>
<td align="left">15</td>
</tr>
<tr class="even">
<td align="left">380</td>
<td align="left">2432</td>
<td align="left">70</td>
<td align="left">5</td>
</tr>
<tr class="odd">
<td align="left">3453</td>
<td align="left">2434</td>
<td align="left">90</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">3407</td>
<td align="left">895</td>
<td align="left">90</td>
<td align="left">15</td>
</tr>
<tr class="odd">
<td align="left">2662</td>
<td align="left">911</td>
<td align="left">85</td>
<td align="left">15</td>
</tr>
</tbody>
</table>
<p>The first step is to store these GCPs in the image metadata using
utility <code>gdal_translate</code>.</p>
<p><strong>Windows</strong></p>
<pre><code>gdal_translate -gcp 418 893 70 15 -gcp 380 2432 70 5 -gcp 3453 2434  90 5 ^
  -gcp 3407 895 90 15 -gcp 2662 911 85 15 ^
  1870_southern-india.jpg india-with-gcp.tif</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdal_translate -gcp 418 893 70 15 -gcp 380 2432 70 5 -gcp 3453 2434  90 5 \
  -gcp 3407 895 90 15 -gcp 2662 911 85 15 \
  1870_southern-india.jpg india-with-gcp.tif</code></pre>
<p>Now that the GCPs are stored in the image, we are ready to do the
georeferencing. Assuming the CRS of the map is a Geographic CRS based on
the Everest 1830 datum, we choose <strong>EPSG:4042</strong> as the
target CRS.</p>
<p>Next, we need to choose the transformation type.
<code>gdalwarp</code> supports the following transformation types</p>
<ul>
<li><em>Polynomial 1,2 or 3</em> using <code>-order</code> option</li>
<li><em>Thin Plate Spline</em> using the <code>-tps</code> option</li>
</ul>
<p>Let’s try <strong>Polynomial 1</strong> transformation and check the
results.</p>
<p><strong>Windows</strong></p>
<pre><code>gdalwarp -t_srs EPSG:4042 -order 1 -tr 0.005 0.005  ^
  india-with-gcp.tif india-reprojected-polynomial.tif ^
  -co COMPRESS=JPEG -co JPEG_QUALITY=50 -co PHOTOMETRIC=YCBCR</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>gdalwarp -t_srs EPSG:4042 -order 1 -tr 0.005 0.005 \
  india-with-gcp.tif india-reprojected-polynomial.tif \
  -co COMPRESS=JPEG -co JPEG_QUALITY=50 -co PHOTOMETRIC=YCBCR</code></pre>
<p><img src="images/gdal/georeference_gcp.png" width="386" style="display: block; margin: auto;" /></p>
</div>
<div id="exercise-5" class="section level3">
<h3>Exercise 5</h3>
<p>Try the Thin-plate-spline transformation on the
<code>india-with-gcp.tif</code> file and save the results as
<code>india-reprojected-tps.tif</code> file. Note the Thin-Place-Splie
option is available at <code>-tps</code> with the <code>gdalwarp</code>
command.</p>
</div>
</div>
<div id="assignment" class="section level2">
<h2>Assignment</h2>
<p>UK’s Department of Environment Food &amp; Rural Affairs (DEFRA)
provides country-wide LiDAR data and products via the <a
href="https://environment.data.gov.uk/DefraDataDownload/?Mode=survey">Defra
Data Services Platform</a> under an open license.</p>
<p>Your data package contains a folder <code>london_1m_dsm</code>. This
folder contains 1m resolution Digital Surface Model (DSM) tiles for
central London generated from a LIDAR survey. The tiles are in the <a
href="https://gdal.org/drivers/raster/aaigrid.html">Arc/Info ASCII
Grid</a> format with the <code>.asc</code> extension. The tiles do not
contain any projection information but the <a
href="https://environment.data.gov.uk/dataset/6f51a299-351f-4e30-a5a3-2511da9688f7">metadata</a>
contains the information that the CRS for the dataset is
<strong>EPSG:27700 British National Grid</strong>.</p>
<p>Apply the skills you learnt in this module to create an output
product suitable for analysis. The result should be a single
georeferenced mosaic in the GeoTIFF format with appropriate
compression.</p>
<ul>
<li>Hint: Use the <code>gdal_translate</code> program with the
<code>-a_srs</code> option to assign a CRS.</li>
</ul>
</div>
</div>
<div id="ogr-tools" class="section level1">
<h1>2. OGR Tools</h1>
<p>We will now learn to process vector data using OGR Tools. These are a
suite of tools that are part of the GDAL package and follow the same
convention. In addition to format translation, the OGR tools also
support running Spatial SQL queries - making them very powerful to build
Spatial ETL pipelines.</p>
<p><a
href="https://www.youtube.com/watch?v=3g6fOVYor4c&amp;list=PLppGmFLhQ1HLVaHVf4TsnJ4HXZBSfxLOK&amp;index=35"
target="_blank"><img
src="https://img.youtube.com/vi/3g6fOVYor4c/mqdefault.jpg"
alt="Start Module Videos" /></a></p>
<p><a
href="https://www.youtube.com/watch?v=3g6fOVYor4c&amp;list=PLppGmFLhQ1HLVaHVf4TsnJ4HXZBSfxLOK&amp;index=35"
target="_blank">Start Module Videos ↗</a></p>
<div id="etl-basics" class="section level2">
<h2>2.1 ETL Basics</h2>
<p>In this section, we will see how we can build an
Extract-Transform-Load (ETL) process in a step-by-step manner. The
example workflow will show you how to</p>
<ol style="list-style-type: decimal">
<li>Read a CSV data source</li>
<li>Convert it to point data layer</li>
<li>Assign it a CRS</li>
<li>Extract a subset</li>
<li>Change the data type of a column</li>
<li>Write the results to a GeoPackage.</li>
</ol>
<div id="read-a-csv-data-source" class="section level3">
<h3>2.1.1 Read a CSV data source</h3>
<p>Your data package has a CSV file called <code>worldcities.csv</code>.
This file contains basic information about major cities in the world
along with their coordinates.</p>
<p>Let’s use the <code>ogrinfo</code> command to inspect the
dataset.</p>
<pre><code>ogrinfo worldcities.csv</code></pre>
<p><img src="images/gdal/ogr_csv01.png" width="75%" style="display: block; margin: auto;" /></p>
<p>The program can open and read the file successfully, but it doesn’t
show any other info. We can use the <code>-al</code> option to actually
read all the lines from the file and combine it with the
<code>-so</code> option to print a summary.</p>
<pre><code>ogrinfo -so -al worldcities.csv</code></pre>
<p><img src="images/gdal/ogr_csv02.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="convert-it-to-point-data-layer" class="section level3">
<h3>2.1.2 Convert it to point data layer</h3>
<p>We now get a summary with the total number of features in the file
along with columns and their types. This is a plain CSV file. Let’s turn
it into a spatial data layer using the X and Y coordinates supplied in
the <code>lng</code> and <code>lat</code> fields. The <code>-oo</code>
option allows us to specify format-specific options. The <a
href="https://gdal.org/drivers/vector/csv.html#reading-csv-containing-spatial-information">OGR
CSV Driver</a> allows specifying a list of column names or a name
pattern (such as <code>Lat*</code>) s using the
<code>X_POSSIBLE_NAMES</code> and <code>Y_POSSIBLE_NAMES</code> options
to specify which columns contain geometry information.</p>
<pre><code>ogrinfo -so -al worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat</code></pre>
<p><img src="images/gdal/ogr_csv03.png" width="75%" style="display: block; margin: auto;" /></p>
<p>OGR is now able to recognize this layer as Point geometry layer.
Let’s write this to a spatial data format. We can use the
<code>ogr2ogr</code> utility to translate between different formats. The
following command creates a new GeoPackage file called
<code>worldcities.gpkg</code> from the CSV file.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr -f GPKG worldcities.gpkg worldcities.csv ^
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat </code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr -f GPKG worldcities.gpkg worldcities.csv \
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat </code></pre>
<p><img src="images/gdal/ogr_csv04.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="assign-it-a-crs" class="section level3">
<h3>2.1.3 Assign it a CRS</h3>
<p>We can open the result in a GIS software and it shows the cities
layer. While the point layer loads fine, it is missing a CRS. We can use
the <code>a_srs</code> option to assign a CRS to the resulting
layer.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr -f GPKG worldcities.gpkg worldcities.csv ^
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr -f GPKG worldcities.gpkg worldcities.csv \
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326</code></pre>
<p><img src="images/gdal/ogr_csv05.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="extract-a-subset" class="section level3">
<h3>2.1.4 Extract a subset</h3>
<p>OGR tools allow executing SQL queries against the data source. It
supports a subset of the SQL capability that is described in the <a
href="https://gdal.org/user/ogr_sql_dialect.html#ogr-sql-dialect">OGR
SQL Syntax</a>. A simple way to select a subset of features is using the
<code>-where</code> option. This allows you to specify an attribute
query to filter the results. Here we modify our command to extract only
the cities where the <code>country</code> column has the value
<strong>India</strong>.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr -f GPKG mycities.gpkg worldcities.csv ^
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 ^
  -where &quot;country = &#39;India&#39;&quot;</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr -f GPKG mycities.gpkg worldcities.csv \
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 \
  -where &quot;country = &#39;India&#39;&quot;</code></pre>
<p><img src="images/gdal/ogr_csv06.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="change-the-data-type-of-a-column" class="section level3">
<h3>2.1.5 Change the data type of a column</h3>
<p>You can also execute any SQL statement on the input data source. This
is a very powerful feature that allows you to filter, join, transform,
and summarize the input data. We can apply this on our data layer to
transform a column type from string to integer. The column
<code>population</code> from the input CSV has the type <em>string</em>.
Since this field is primarily used to store integer values, we can use
the <code>CAST()</code> SQL function to change the type to
<em>integer</em>. The <code>SELECT</code> statement also allows us to
pick only the relevant fields that will get written to the output.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr -f GPKG mycities.gpkg worldcities.csv ^
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 ^
  -sql &quot;SELECT city, country, CAST(population AS integer) as population ^
    from worldcities where country = &#39;India&#39;&quot;</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr -f GPKG mycities.gpkg worldcities.csv \
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 \
  -sql &quot;SELECT city, country, CAST(population AS integer) as population \
    from worldcities where country = &#39;India&#39;&quot;</code></pre>
<p><img src="images/gdal/ogr_csv07.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="rename-the-layer-in-geopackage." class="section level3">
<h3>2.1.6 Rename the layer in GeoPackage.</h3>
<p>Lastly, we can rename the name of the output layer using the
<code>-nln</code> option.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr -f GPKG mycities.gpkg worldcities.csv ^
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 ^
  -sql &quot;SELECT city, country, CAST(population AS integer) as population ^
  from worldcities where country = &#39;India&#39;&quot; -nln mycities</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr -f GPKG mycities.gpkg worldcities.csv \
  -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 \
  -sql &quot;SELECT city, country, CAST(population AS integer) as population \
  from worldcities where country = &#39;India&#39;&quot; -nln mycities</code></pre>
<p><img src="images/gdal/ogr_csv08.png" width="75%" style="display: block; margin: auto;" /></p>
<p>This shows the power of OGR command-line tools. In just a single
line, we can read, filter, transform and write the results in any output
format supported by OGR.</p>
</div>
<div id="exercise-6" class="section level3">
<h3>Exercise 6</h3>
<p>Write a command using <code>ogr2ogr</code> that performs the
following operations.</p>
<ul>
<li>Read the newly created <code>mycities</code> layer from the
<code>mycities.gpkg</code> file.</li>
<li>Reproject the layer to a new CRS <strong>EPSG:7755</strong> (WGS84 /
India NSF LCC).</li>
<li>Save the results as a shapefile <code>mycities.shp</code></li>
</ul>
<p>All of the above operations should be done in a single-command. Once
you arrive at a solution, see if you can improve it by working on the
following challenges:</p>
<ul>
<li><p>Challenge 1: You will get a warning that some field values could
not be written correctly. This is because the default encoding for the
Shapefile format is <em>ISO-8859-1</em> - which doesn’t support
non-latin characters. You can specify the encoding to
<strong>UTF-8</strong> using the <code>-lco</code> option in
<code>ogr2ogr</code> command. <em>Hint: Review the <a
href="https://gdal.org/drivers/vector/shapefile.html#layer-creation-options">Layer
Creation Options</a> for the shapefile driver to see the correct
syntax</em>.</p></li>
<li><p>Challenge 2: While you are exploring the Layer Creation Options,
add an option to create a spatial index on the output shapefile.
<em>Hint: You can specify the <code>-lco</code> option multiple times in
the command.</em></p></li>
</ul>
</div>
</div>
<div id="merging-vector-files" class="section level2">
<h2>2.2 Merging Vector Files</h2>
<p>Another useful utility provided by OGR is <a
href="https://gdal.org/programs/ogrmerge.html">ogrmerge.py</a>. This
command can merge several vector layers into a single data layer. It
also has several options to control how the datasets are merged - making
it a very handy tool for data processing tasks.</p>
<p>We will work with several GeoJSON files containing locations of
earthquakes. Your data package contains several GEOJSON files in the
<code>earthquakes/</code> directory. We will merge these 12 files into a
single file. Switch to the directory</p>
<pre><code>cd earthquakes</code></pre>
<p>We will create a geopackage file by merging all files in the
directory. Windows users may need to specify the full path to
<code>ogrmerge.py</code> script as follows.</p>
<p><em>Windows</em></p>
<pre><code>python %CONDA_PREFIX%\Scripts\ogrmerge.py -o earthquakes.gpkg *.geojson</code></pre>
<p><em>Mac/Linux</em></p>
<pre><code>ogrmerge.py -o earthquakes.gpkg *.geojson</code></pre>
<p><img src="images/gdal/ogrmerge01.png" width="75%" style="display: block; margin: auto;" /></p>
<p>The result will be a single geopackage containing 12 layers - one for
each source file. For most applications, it will be preferable to
combine source files into a single layer. We can use the
<code>-single</code> option to indicate we want a single layer as the
output. We also use the <code>-nln</code> option to specify the name of
the merged layer. Since the GeoPackage dataset already exists, we need
to specify the <code>-overwrite_ds</code> to overwrite the file with the
new content.</p>
<p><em>Windows</em></p>
<pre><code>python %CONDA_PREFIX%\Scripts\ogrmerge.py -o earthquakes.gpkg *.geojson ^
  -single -nln all_earthquakes -overwrite_ds</code></pre>
<p><em>Mac/Linux</em></p>
<pre><code>ogrmerge.py -o earthquakes.gpkg *.geojson \
  -single -nln all_earthquakes -overwrite_ds</code></pre>
<p>Now you will have a single layer named <code>all_earthquakes</code>
in the GeoPackage containing all earthquakes recorded during the
year.</p>
<p><img src="images/gdal/ogrmerge02.png" width="75%" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Tip: There is a very useful option <code>-src_layer_field_name</code>
that can add a new field to the output layer containing the name of the
input file which contributed that particular record.</p>
</blockquote>
<div id="exercise-7" class="section level3">
<h3>Exercise 7</h3>
<p>Create a new GeoPackage <code>large_earthquakes.gpkg</code>
containing only the earthquakes with magnitude greater than 4.5.</p>
<ul>
<li>Use <code>ogr2ogr</code> utility to read the
<code>earthquakes.gpkg</code> file created in the previous section.</li>
<li>Use the <code>-where</code> option to write the query to filter the
records where <code>mag</code> field has values greater
<code>&gt;4.5</code>.</li>
</ul>
<p>Challenge: Instead of creating a new geopackage, add a layer named
<code>large_earthquakes</code> to the existing
<code>earthquakes.gpkg</code> file. <em>Hint: Use the
<code>-update</code> option along with <code>-nln</code> to specify the
layer name.</em></p>
</div>
</div>
<div id="geoprocessing-and-spatial-queries" class="section level2">
<h2>2.3 Geoprocessing and Spatial Queries</h2>
<p>We have seen examples of using SQL queries in OGR commands. So far we
have used the queries that adhere to the OGR SQL Dialect. OGR Tools also
have support <a
href="https://gdal.org/user/sql_sqlite_dialect.html">SQLite dialect</a>.
The major advantage of using the SQLite dialect is that you can use
Spatial SQL functions provided by <a
href="http://www.gaia-gis.it/spatialite/">Spatialite</a>. This enables a
wide range of applications where you can do spatial queries using OGR
tools. A major difference when using the SQLite dialect is that you must
specify the geometry column explicitly.</p>
<p>Let’s do some geoprocessing and see how we can use spatial queries
with OGR Tools. Your data package as a geopackage file
<code>spatial_query.gpkg</code>. This geopackage contains 2 layers.</p>
<ul>
<li><code>metro_stations</code>: Point layer with metro rail locations
in the city of Melbourne.</li>
<li><code>bars_and_pubs</code>: Point layer with locations of bars and
pubs in the city of Melbourne.</li>
</ul>
<p>Let’s see how we can add a new layer to this geopackage with all bars
and pubs that are within 500m of a metro station.</p>
<div id="reprojecting-vector-layers" class="section level3">
<h3>2.3.1 Reprojecting Vector Layers</h3>
<p>The source data layers are in the CRS <code>EPSG:4326</code>. As we
want to run a spatial query with distance in meters, let’s reproject
both the layers to a projected CRS. Let’s use the <code>ogr2ogr</code>
command to reproject both the input layers and save them into the same
geopackage. We can use <code>-t_srs</code> option allows us to specify
<strong>EPSG:7855</strong> (GDA2020 / MGA Zone 55) as the target
projection. the <code>-update</code> option along with <code>-nln</code>
tells <code>ogr2ogr</code> to create a new layer and save it in the same
geopackage.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr -t_srs EPSG:7855 spatial_query.gpkg spatial_query.gpkg ^
  bars_and_pubs -update -nln bars_and_pubs_reprojected
ogr2ogr -t_srs EPSG:7855 spatial_query.gpkg spatial_query.gpkg ^
  metro_stations -update -nln metro_stations_reprojected</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr -t_srs EPSG:7855 spatial_query.gpkg spatial_query.gpkg \
  bars_and_pubs -update -nln bars_and_pubs_reprojected
ogr2ogr -t_srs EPSG:7855 spatial_query.gpkg spatial_query.gpkg \
  metro_stations -update -nln metro_stations_reprojected</code></pre>
<p><img src="images/gdal/geoprocessing1.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="creating-buffers" class="section level3">
<h3>2.3.2 Creating Buffers</h3>
<p>Let’s buffer the <code>metro_stations_reprojected</code> layer using
a distance of <strong>500</strong> meters. Here we specify the SQL query
with the <code>-sql</code> option. Note the use of the
<code>ST_Buffer()</code> function which is provided by the Spatialite
engine. We need to specify <code>-dialect SQLITE</code> as the query
uses spatial functions.</p>
<blockquote>
<p>Spatial database functions often have the <code>ST_</code> prefix. ST
stands for <strong>Spatial Type</strong>.</p>
</blockquote>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr spatial_query.gpkg spatial_query.gpkg -update -nln metro_stations_buffer ^
  -sql &quot;SELECT m.station, ST_Buffer(m.geom, 500) as geom FROM ^
    metro_stations_reprojected m&quot; -dialect SQLITE </code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr spatial_query.gpkg spatial_query.gpkg -update -nln metro_stations_buffer \
  -sql &quot;SELECT m.station, ST_Buffer(m.geom, 500) as geom FROM \
    metro_stations_reprojected m&quot; -dialect SQLITE </code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/geoprocessing2.png" alt="Metro Station Buffers" width="75%" />
<p class="caption">
Metro Station Buffers
</p>
</div>
<p>This query results in individual overlapping buffers. We can dissolve
the buffers using <code>ST_Collect()</code> function.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr spatial_query.gpkg spatial_query.gpkg -update ^
  -nln metro_stations_buffer_dissolved -sql &quot;SELECT ST_Union(d.geom) as geom ^
    FROM (SELECT ST_Collect(buffer(m.geom, 500)) as geom ^
    FROM metro_stations_reprojected m) as d&quot; -dialect SQLITE</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr spatial_query.gpkg spatial_query.gpkg -update \
  -nln metro_stations_buffer_dissolved -sql &quot;SELECT ST_Union(d.geom) as geom \
  FROM (SELECT ST_Collect(buffer(m.geom, 500)) as geom \
  FROM metro_stations_reprojected m) as d&quot; -dialect SQLITE</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/geoprocessing3.png" alt="Dissolved Buffers" width="75%" />
<p class="caption">
Dissolved Buffers
</p>
</div>
</div>
<div id="performing-spatial-queries" class="section level3">
<h3>2.3.3 Performing Spatial Queries</h3>
<p>Now that we have a polygon layer with the buffer region around the
metro stations, we can use the <a
href="https://gdal.org/programs/ogr_layer_algebra.html"><code>ogr_layer_algebra.py</code></a>
tool to select the metro stations falling within the buffer region. This
tool can perform various types of spatial queries, including
Intersection, Difference (Erase), Union etc. We will use the
<em>Clip</em> mode to select features from the input layer clipped to
the features from the secondary layer.</p>
<p><strong>Windows</strong></p>
<pre><code>python %CONDA_PREFIX%\Scripts\ogr_layer_algebra.py Clip ^
  -input_ds spatial_query.gpkg -input_lyr bars_and_pubs_reprojected ^
  -method_ds spatial_query.gpkg -method_lyr metro_stations_buffer_dissolved ^
  -output_ds output.gpkg -output_lyr selected -nlt POINT</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr_layer_algebra.py Clip \
  -input_ds spatial_query.gpkg -input_lyr bars_and_pubs_reprojected \
  -method_ds spatial_query.gpkg -method_lyr metro_stations_buffer_dissolved \
  -output_ds output.gpkg -output_lyr selected -nlt POINT</code></pre>
<p><img src="images/gdal/geoprocessing4.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="data-cleaning" class="section level3">
<h3>2.3.4 Data Cleaning</h3>
<p>The previous query does the job and you find all points that are
within the buffer region. But you will notice that there are many
duplicate points at the same location. Upon inspecting, you will note
that the source data contains multiple features for each establishment
from different years. We can run a final SQL query to de-duplicate the
data by selecting the feature from the latest year for each
establishment. Note that some column names have spaces in the names, so
we enclose them in double-quotes.</p>
<p><strong>Windows</strong></p>
<pre><code>ogr2ogr -t_srs EPSG:4326 output.gpkg output.gpkg -update ^
  -nln cleaned -sql &quot;SELECT t1.* FROM selected t1 ^
  JOIN (SELECT \&quot;Property ID\&quot;, MAX(\&quot;Census year\&quot;) as year FROM selected ^
  GROUP BY \&quot;Property ID\&quot;) t2 ON t1.\&quot;Property ID\&quot; = t2.\&quot;Property ID\&quot; ^
  AND t1.\&quot;Census year\&quot; = t2.year&quot;</code></pre>
<p><strong>Mac/Linux</strong></p>
<pre><code>ogr2ogr -t_srs EPSG:4326 output.gpkg output.gpkg -update \
  -nln cleaned -sql &quot;SELECT t1.* FROM selected t1 \
  JOIN (SELECT \&quot;Property ID\&quot;, MAX(\&quot;Census year\&quot;) as year FROM selected \
  GROUP BY \&quot;Property ID\&quot;) t2 ON t1.\&quot;Property ID\&quot; = t2.\&quot;Property ID\&quot; \
  AND t1.\&quot;Census year\&quot; = t2.year&quot;</code></pre>
<p><img src="images/gdal/geoprocessing5.png" width="75%" style="display: block; margin: auto;" /></p>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div id="running-commands-in-batch" class="section level1">
<h1>3. Running commands in batch</h1>
<p>You can run the GDAL/OGR commands in a loop using Python. For
example, if we wanted to convert the format of the images from JPEG200
to GeoTiff for all files in a directory, we would want to run a command
like below for every image. Here we want the <code>{input}</code> and
<code>{output}</code> values to be determined from the files in a
directory.</p>
<pre><code>gdal_translate -of GTiff -co COMPRESS=JPEG {input} {output}</code></pre>
<p>But it would be a lot of manual effort if you want to run the
commands on hundreds of input files. Here’s where a simple python script
can help you automate running the commands in a batch. The data
directory contains a file called <code>batch.py</code> with the
following python code.</p>
<div class="sourceCode" id="cb91"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb91-2"><a href="#cb91-2" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" tabindex="-1"></a>input_dir <span class="op">=</span> <span class="st">&#39;naip&#39;</span></span>
<span id="cb91-4"><a href="#cb91-4" tabindex="-1"></a></span>
<span id="cb91-5"><a href="#cb91-5" tabindex="-1"></a>command_string <span class="op">=</span> <span class="st">&#39;gdal_translate -of GTiff -co COMPRESS=JPEG </span><span class="sc">{input}</span><span class="st"> </span><span class="sc">{output}</span><span class="st">&#39;</span></span>
<span id="cb91-6"><a href="#cb91-6" tabindex="-1"></a><span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> os.listdir(input_dir):</span>
<span id="cb91-7"><a href="#cb91-7" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">file</span>.endswith(<span class="st">&#39;.jp2&#39;</span>):</span>
<span id="cb91-8"><a href="#cb91-8" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> os.path.join(input_dir, <span class="bu">file</span>)</span>
<span id="cb91-9"><a href="#cb91-9" tabindex="-1"></a>    filename <span class="op">=</span> os.path.splitext(os.path.basename(<span class="bu">file</span>))[<span class="dv">0</span>]</span>
<span id="cb91-10"><a href="#cb91-10" tabindex="-1"></a>    output <span class="op">=</span>  os.path.join(input_dir, filename <span class="op">+</span> <span class="st">&#39;.tif&#39;</span>)</span>
<span id="cb91-11"><a href="#cb91-11" tabindex="-1"></a>    command <span class="op">=</span> command_string.<span class="bu">format</span>(<span class="bu">input</span><span class="op">=</span><span class="bu">input</span>, output<span class="op">=</span>output)</span>
<span id="cb91-12"><a href="#cb91-12" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;Running -&gt;&#39;</span>, command)</span>
<span id="cb91-13"><a href="#cb91-13" tabindex="-1"></a>    os.system(command)</span></code></pre></div>
<p>In Anaconda Prompt, run the following command from
<code>gdal-tools</code> directory to start batch processing on all tiles
contained in the <code>naip/</code> directory.</p>
<pre><code>python batch.py</code></pre>
<p>The data directory also contains an example of running the batch
commands in parallel using python’s built-in multiprocessing library. If
your system has multi-core CPU, running commands in parallel like this
on multiple threads can give you performance boost over running them in
series.</p>
<div class="sourceCode" id="cb93"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb93-2"><a href="#cb93-2" tabindex="-1"></a><span class="im">from</span> multiprocessing <span class="im">import</span> Pool</span>
<span id="cb93-3"><a href="#cb93-3" tabindex="-1"></a></span>
<span id="cb93-4"><a href="#cb93-4" tabindex="-1"></a>input_dir <span class="op">=</span> <span class="st">&#39;naip&#39;</span></span>
<span id="cb93-5"><a href="#cb93-5" tabindex="-1"></a>command_string <span class="op">=</span> <span class="st">&#39;gdal_translate -of GTiff -co COMPRESS=JPEG </span><span class="sc">{input}</span><span class="st"> </span><span class="sc">{output}</span><span class="st">&#39;</span></span>
<span id="cb93-6"><a href="#cb93-6" tabindex="-1"></a></span>
<span id="cb93-7"><a href="#cb93-7" tabindex="-1"></a>num_cores <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb93-8"><a href="#cb93-8" tabindex="-1"></a></span>
<span id="cb93-9"><a href="#cb93-9" tabindex="-1"></a><span class="kw">def</span> process(<span class="bu">file</span>):</span>
<span id="cb93-10"><a href="#cb93-10" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> os.path.join(input_dir, <span class="bu">file</span>)</span>
<span id="cb93-11"><a href="#cb93-11" tabindex="-1"></a>    filename <span class="op">=</span> os.path.splitext(os.path.basename(<span class="bu">file</span>))[<span class="dv">0</span>]</span>
<span id="cb93-12"><a href="#cb93-12" tabindex="-1"></a>    output <span class="op">=</span>  os.path.join(input_dir, filename <span class="op">+</span> <span class="st">&#39;.tif&#39;</span>)</span>
<span id="cb93-13"><a href="#cb93-13" tabindex="-1"></a>    command <span class="op">=</span> command_string.<span class="bu">format</span>(<span class="bu">input</span><span class="op">=</span><span class="bu">input</span>, output<span class="op">=</span>output)</span>
<span id="cb93-14"><a href="#cb93-14" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&#39;Running -&gt;&#39;</span>, command)</span>
<span id="cb93-15"><a href="#cb93-15" tabindex="-1"></a>    os.system(command)</span>
<span id="cb93-16"><a href="#cb93-16" tabindex="-1"></a>    </span>
<span id="cb93-17"><a href="#cb93-17" tabindex="-1"></a>files <span class="op">=</span> [<span class="bu">file</span> <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> os.listdir(input_dir) <span class="cf">if</span> <span class="bu">file</span>.endswith(<span class="st">&#39;.jp2&#39;</span>)]</span>
<span id="cb93-18"><a href="#cb93-18" tabindex="-1"></a></span>
<span id="cb93-19"><a href="#cb93-19" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:</span>
<span id="cb93-20"><a href="#cb93-20" tabindex="-1"></a>  p <span class="op">=</span> Pool(num_cores)</span>
<span id="cb93-21"><a href="#cb93-21" tabindex="-1"></a>  p.<span class="bu">map</span>(process, files)</span></code></pre></div>
<p>The script runs the commands both in parallel and serial mode and
prints the time taken by each of them.</p>
<pre><code>python batch_parallel.py</code></pre>
<div style="page-break-after: always;"></div>
</div>
<div id="automating-and-scheduling-gdalogr-jobs" class="section level1">
<h1>4. Automating and Scheduling GDAL/OGR Jobs</h1>
<p>The easiest way to run commands on a schedule on a Linux-based server
is using a <a
href="https://towardsdatascience.com/create-your-first-cronjob-on-the-linux-server-74e2fdc76e78">Cron
Job</a>.</p>
<p>You will have to edit your <code>crontab</code> and schedule the
execution of your script (either Shell Script or Python Script). The key
is to activate the conda environment before execution of the script.</p>
<p>Assuming you have created a script to execute some GDAL/OGR commands
and placed it at <code>/usr/local/bin/batch.py</code>, here’s a sample
crontab entry that executes it every morning at 6am.</p>
<pre><code>0 6 * * * conda activate gdal;python /use/local/bin/batch.py; conda deactivate</code></pre>
<p>If you get an error while execution, you may have to include some
environment variables in the crontab file so it can find
<code>conda</code> correctly. <a
href="https://unix.stackexchange.com/questions/454957/cron-job-to-run-under-conda-virtual-environment">Learn
more</a>.</p>
<pre><code>SHELL=/bin/bash
BASH_ENV=~/.bashrc
0 6 * * * conda activate gdal;python batch-parallel.py; conda deactivate</code></pre>
</div>
<div id="tips-for-improving-performance" class="section level1">
<h1>Tips for Improving Performance</h1>
<div id="configuration-options" class="section level2">
<h2>Configuration Options</h2>
<p>GDAL has several <a
href="https://gdal.org/user/configoptions.html">configuration
options</a> that can be tweaked to help with faster processing.</p>
<ul>
<li><code>--config GDAL_CACHEMAX 512</code>: This option is the one that
helps speed up most GDAL commands by allowing them to use larger amount
of RAM (512 MB) reading/writing data.</li>
<li><code>--config GDAL_NUM_THREADS ALL_CPUS</code>: This option helps
speed up write speed by using multiple threads for compression.</li>
<li><code>--debug on</code>: Turn on debugging mode. This prints
additional information that may help you find performance
bottlenecks.</li>
</ul>
</div>
<div id="multithreading" class="section level2">
<h2>Multithreading</h2>
<p><code>gdalwarp</code> utility supports multithreaded processing.
There are 2 different options for parallel processing.</p>
<ul>
<li><code>-multi</code>: This option parallelizes I/O and CPU
operations.</li>
<li><code>-wo NUM_THREADS=ALL_CPUS</code>: This option parallelizes CPU
operations over several cores.</li>
</ul>
<p>There is also another option that allows <code>gdalwarp</code> to use
more RAM for caching. This option is very helpful to speed up operations
on large rasters</p>
<ul>
<li><code>-wm</code>: Set a higher memory for caching</li>
</ul>
<p>All of these options can be combined that may result in faster
processing of the data.</p>
<pre><code>gdalwarp -cutline aoi.shp  -crop_to_cutline naip.vrt aoi.tif -co COMPRESS=DEFLATE -co TILED=YES -multi -wo NUM_THREADS=ALL_CPUS -wm 512 --config GDAL_CACHEMAX 512</code></pre>
</div>
</div>
<div id="supplement" class="section level1">
<h1>Supplement</h1>
<div id="check-supported-formats-and-capabilities"
class="section level2">
<h2>Check Supported Formats and Capabilities</h2>
<p>The GDAL binaries are built to include support for many common data
formats. To check what formats are supported in your GDAL distribution,
you can run the following command</p>
<pre><code>gdalinfo --formats</code></pre>
<p>Alternatively the <code>--format</code> flag can be used with any
other utilities like <code>gdal_translate</code> or <code>ogrinfo</code>
to obtain this list.</p>
<p>The output lists the shortnames of all the drivers, whether supports
vector or raster data along with abbreviations indicating the
capabilities.</p>
<table>
<thead>
<tr class="header">
<th>Abbreviation</th>
<th>Capabilities</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>r</td>
<td>read</td>
</tr>
<tr class="even">
<td>ro</td>
<td>read only</td>
</tr>
<tr class="odd">
<td>w</td>
<td>write (create dataset)</td>
</tr>
<tr class="even">
<td>w+</td>
<td>write with (support to update)</td>
</tr>
<tr class="odd">
<td>s</td>
<td>supports subdatasets</td>
</tr>
<tr class="even">
<td>v</td>
<td>supports virtual access - eg. /vsimem/</td>
</tr>
</tbody>
</table>
<p>That means an abbreviation of <code>rov</code> indicates that it is a
read-only format that supports virtual access.</p>
<p>QGIS distributes versions of GDAL that also has support for non-open
formats, such as MrSID. You can use the commands from the included GDAL
distribution. The location will depend on the platform and the
distribution. Below is an example of how to set the correct path and
environment variables for using that.</p>
<p>Open a Command Prompt/Terminal and run the following to set the
correct path.</p>
<p><strong>Windows</strong></p>
<pre><code>set OSGEO4W_ROOT=C:\OSGeo4W
call &quot;%OSGEO4W_ROOT%\bin\o4w_env.bat&quot; 
set PATH=%OSGEO4W_ROOT%\bin;%OSGEO4W_ROOT%\apps\qgis-ltr\bin</code></pre>
<p><strong>Mac</strong></p>
<pre><code>export PATH=/Applications/$QGIS_VERSION.app/Contents/MacOS/bin:$PATH</code></pre>
<p>Running <code>gdalinfo --formats</code> will not list MrSID and other
proprietary formats.</p>
</div>
<div id="extracting-image-metadata-and-statistics"
class="section level2">
<h2>Extracting Image Metadata and Statistics</h2>
<p>You can run <code>gdalinfo</code> command with the <code>-json</code>
option which returns the info as a JSON string. This allows you to
programatically access the information and parse it.</p>
<p>Let’s say we want to extract the maximum value of the
<code>merged.vrt</code> created in the <a href="#merging-tiles">Merging
Tiles</a> section. We can get the output of the command as a JSON by
supplying the <code>-json</code> option.</p>
<pre><code>gdalinfo -stats -json merged.vrt</code></pre>
<p>Next, we need a way to parse the JSON and extract the fields we are
interested in. There are many other command-line utilities designed to
do just that. Here we use the popular JSON processing utility <a
href="https://stedolan.github.io/jq/">jq</a>. You can download and
install the <code>jq CLI</code> for your operating system and make sure
it is in the system path. Then we can extract the required data using
the <code>jq</code> query like below.</p>
<pre><code>gdalinfo -stats -json merged.vrt | jq &quot;.bands[0].maximum&quot;</code></pre>
<p><img src="images/gdal/jq.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Alternatively, you can also run the command via Python and use the
<code>json</code> module to parse and extract the results. The code
below shows how to extract the min and max values for each of the SRTM
tiles used in the example earlier.</p>
<div class="sourceCode" id="cb103"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb103-2"><a href="#cb103-2" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb103-3"><a href="#cb103-3" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb103-4"><a href="#cb103-4" tabindex="-1"></a></span>
<span id="cb103-5"><a href="#cb103-5" tabindex="-1"></a>input_dir <span class="op">=</span> <span class="st">&#39;srtm&#39;</span></span>
<span id="cb103-6"><a href="#cb103-6" tabindex="-1"></a></span>
<span id="cb103-7"><a href="#cb103-7" tabindex="-1"></a>command <span class="op">=</span> <span class="st">&#39;gdalinfo -stats -json </span><span class="sc">{input}</span><span class="st">&#39;</span></span>
<span id="cb103-8"><a href="#cb103-8" tabindex="-1"></a><span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> os.listdir(input_dir):</span>
<span id="cb103-9"><a href="#cb103-9" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">file</span>.endswith(<span class="st">&#39;.hgt&#39;</span>):</span>
<span id="cb103-10"><a href="#cb103-10" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> os.path.join(input_dir, <span class="bu">file</span>)</span>
<span id="cb103-11"><a href="#cb103-11" tabindex="-1"></a>    filename <span class="op">=</span> os.path.splitext(os.path.basename(<span class="bu">file</span>))[<span class="dv">0</span>]</span>
<span id="cb103-12"><a href="#cb103-12" tabindex="-1"></a>    output <span class="op">=</span> subprocess.check_output(command.<span class="bu">format</span>(<span class="bu">input</span><span class="op">=</span><span class="bu">input</span>), shell<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb103-13"><a href="#cb103-13" tabindex="-1"></a>    info_dict <span class="op">=</span> json.loads(output)</span>
<span id="cb103-14"><a href="#cb103-14" tabindex="-1"></a>    bands <span class="op">=</span> info_dict[<span class="st">&#39;bands&#39;</span>]</span>
<span id="cb103-15"><a href="#cb103-15" tabindex="-1"></a>    <span class="cf">for</span> band <span class="kw">in</span> bands:</span>
<span id="cb103-16"><a href="#cb103-16" tabindex="-1"></a>      band_id <span class="op">=</span> band[<span class="st">&#39;band&#39;</span>]</span>
<span id="cb103-17"><a href="#cb103-17" tabindex="-1"></a>      <span class="bu">min</span> <span class="op">=</span> band[<span class="st">&#39;minimum&#39;</span>]</span>
<span id="cb103-18"><a href="#cb103-18" tabindex="-1"></a>      <span class="bu">max</span> <span class="op">=</span> band[<span class="st">&#39;maximum&#39;</span>]</span>
<span id="cb103-19"><a href="#cb103-19" tabindex="-1"></a>      <span class="bu">print</span>(<span class="st">&#39;</span><span class="sc">{}</span><span class="st">,</span><span class="sc">{}</span><span class="st">,</span><span class="sc">{}</span><span class="st">,</span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(filename, band_id, <span class="bu">min</span>, <span class="bu">max</span>))</span></code></pre></div>
</div>
<div id="validating-cogs" class="section level2">
<h2>Validating COGs</h2>
<p>If you want to check whether a given GeoTIFF file is a valid
Cloud-Optimized GeoTIFF (COG) or not, there are several methods.</p>
<ol style="list-style-type: decimal">
<li>Using the <code>rio</code> command-line utility</li>
</ol>
<p>Rasterio provides a command-line utility called <a
href="https://rasterio.readthedocs.io/en/stable/cli.html"
target="_blank">rio</a> to perform various raster operations on the
command-line. The <a href="https://cogeotiff.github.io/rio-cogeo/"
target="_blank">rio-cogeo</a> plugin to Rasterio adds support for
creation and validation of COGs.</p>
<p>You can install the required libraries in your conda environment as
follows.</p>
<pre><code>conda create --name cogeo
conda activate cogeo
conda install -c conda-forge rasterio rio-cogeo</code></pre>
<p>Once installed, you can validate a COG using the
<code>rio cogeo</code> command.</p>
<pre><code>rio cogeo validate merged_cog.tif</code></pre>
<p>This works on cloud-hosted files as well.</p>
<pre><code>rio cogeo validate /vsicurl/https://storage.googleapis.com/spatialthoughts-public-data/ntl/viirs/viirs_ntl_2021_global.tif</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Using Python</li>
</ol>
<p>You can use the <a
href="https://github.com/rouault/cog_validator/blob/master/validate_cloud_optimized_geotiff.py">validate_cloud_optimized_geotiff.py</a>
script to check whether a file is a valid COG.</p>
<pre><code>python validate_cloud_optimized_geotiff.py merged_cog.tif</code></pre>
<p>You can also use it in your Python script as follows</p>
<pre><code>import validate_cloud_optimized_geotiff.py
validate_cloud_optimized_geotiff.validate(&#39;merged_cog.tif&#39;)</code></pre>
</div>
<div id="creating-contours" class="section level2">
<h2>Creating Contours</h2>
<blockquote>
<p>Note : The <code>merged.tif</code> file used below was created in the
<a href="#merging-tiles">Merging Tiles</a> section.</p>
</blockquote>
<p>The GDAL package comes with the utility <code>gdal_countour</code>
that creates contour lines and polygons from DEMs.</p>
<p>You can specify the interval between contour lines using the
<code>-i</code> option.</p>
<pre><code>gdal_contour merged.tif contours.gpkg -i 500</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/contour1.png" alt="Contour Lines from DEM" width="75%" />
<p class="caption">
Contour Lines from DEM
</p>
</div>
<p>Running the command with default options generates a vector layer
with contours but they do not have any attributes. If you want to label
your contour lines in your map, you may want to create contours with
elevation values as an attribute. You can use the <code>-a</code> option
and specify the name of the attribute.</p>
<pre><code>gdal_contour merged.tif contours.gpkg -i 500 -a elev</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/contour2.png" alt="Contour Lines with Elevation Attribute" width="75%" />
<p class="caption">
Contour Lines with Elevation Attribute
</p>
</div>
<p>You can also create polygon contours. Polygon contours are useful in
some applications such as hydrology where you want to derive average
depth of rainfall in the region between isohyets. You can specify the
<code>-p</code> option to create polygon contours. The options
<code>-amin</code> and <code>-amax</code> can be provided to specify the
attribute names which will store the min and max elevation for each
polygon. The command below creates a contour shapefile for the input
<code>merged.tif</code> DEM.</p>
<pre><code>gdal_contour merged.tif contour_polygons.shp -i 500 -p -amin MINELEV -amax MAXELEV</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/contour3.png" alt="Contour Polygons with Elevation Attributes" width="75%" />
<p class="caption">
Contour Polygons with Elevation Attributes
</p>
</div>
</div>
<div id="creating-colorized-imagery" class="section level2">
<h2>Creating Colorized Imagery</h2>
<p>We can use <code>gdaldem color-relief</code> command to apply a color
palette to any one-band image to create a rendered image.</p>
<p>We create a file <code>ntl_colormap.txt</code> containing the pixel
intensity values mapped to RGB colors. The key <code>nv</code> is used
to assign a color to NoData values.</p>
<pre><code>0 0 0 4
20 145 43 129
40 251 133 96
50 254 216 154
60 252 253 191
nv 255 255 255</code></pre>
<p>Apply the colormap to the single-band nighttime lights image.</p>
<pre><code>gdaldem color-relief \
  /vsicurl/https://storage.googleapis.com/spatialthoughts-public-data/ntl/viirs/viirs_ntl_2021_india.tif \
  ntl_colormap.txt ntl_colorized.tif</code></pre>
<p>Convert the colorized GeoTIFF to a PNG. Specify the value 255 to set
the transparency for the NoData values.</p>
<pre><code>gdal_translate -of PNG -a_nodata 255 ntl_colorized.tif ntl_colorized.png</code></pre>
<p><img src="images/gdal/ntl_colorized.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="creating-colorized-hillshade" class="section level2">
<h2>Creating Colorized Hillshade</h2>
<p>If you want to merge hillshade and color-relief to create a colored
shaded relief map, you can use use <code>gdal_calc.py</code> to create
do gamma and overlay calculations to combine the 2 rasters. <a
href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<pre><code>gdal_calc.py -A hillshade.tif --outfile=gamma_hillshade.tif \
  --calc=&quot;uint8(((A / 255.)**(1/0.5)) * 255)&quot;</code></pre>
<pre><code>gdal_calc.py -A gamma_hillshade.tif -B colorized.tif --allBands=B \
--calc=&quot;uint8( ( \
                 2 * (A/255.)*(B/255.)*(A&lt;128) + \
                 ( 1 - 2 * (1-(A/255.))*(1-(B/255.)) ) * (A&gt;=128) \
               ) * 255 )&quot; --outfile=colorized_hillshade.tif</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/colorized_hillshade.png" alt="Colorized Shaded Relief" width="75%" />
<p class="caption">
Colorized Shaded Relief
</p>
</div>
</div>
<div id="removing-jpeg-compression-artifacts" class="section level2">
<h2>Removing JPEG Compression Artifacts</h2>
<p>Applying JPEG compression on aerial or drone imagery can cause the
results to have edge artifacts. Since JPEG is a lossy compression
algorithm, it causes no-data values (typically 0) being converted to
non-zero values. This causes problems when you want to mosaic different
tiles, or mask the black pixels. Fortunately, GDAL comes with a handy
tool called <a
href="https://gdal.org/programs/nearblack.html">nearblack</a> that is
designed to solve this problem. You can specify a tolerance value to
remove edge pixels that may not be exactly 0. It scans the image inwards
till it finds these near-black pixel values and masks them. Let’s say we
have a mosaic of JPEG compressed imagery without an alpha band and we
want to set a mask. If we simply set 0 as nodata value, you will end up
with edge artifacts, along with many dark pixels within the mosaic
(building shadows/water etc.) being masked. Instead we use the
<code>nearblack</code> program to set edge pixels with value 0-5 being
considered nodata.</p>
<pre><code>nearblack -near 5 -setmask -o aoi_masked.tif aoi.tif \
  -co COMPRESS=JPEG -co TILED=YES -co PHOTOMETRIC=YCBCR</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/nearblack.png" alt="JPEG Artifacts Cleaned by GDAL nearblack" width="75%" />
<p class="caption">
JPEG Artifacts Cleaned by GDAL nearblack
</p>
</div>
</div>
<div id="splitting-a-mosaic-into-tiles" class="section level2">
<h2>Splitting a Mosaic into Tiles</h2>
<p>When delivering large mosaics, it is a good idea to split your large
input file into smaller chunks. If you are working with a very large
mosaic, splitting it into smaller chunks and processing them
independently can help overcome memory issues. This is also helpful to
prepare the satellite imagery for Deep Learning. GDAL ships with a handy
script called <code>gdal_retile.py</code> that is designed for this
task.</p>
<p>Let’s say we have a large GeoTIFF file <code>aoi.tif</code> and want
to split it into tiles of 256 x 256 pixels, with an overlap to 10
pixels.</p>
<p>First we create a directory where the output tiles will be
written.</p>
<pre><code>mkdir tiles</code></pre>
<p>We can now use the following command to split the file and write the
output to the <code>tiles</code> directory.</p>
<pre><code>gdal_retile.py -ps 256 256 -overlap 10 -targetDir tiles/ aoi.tif</code></pre>
<p>This will create smaller GeoTiff files. If you want to train a Deep
Learning model, you would typically require JPEG or PNG tiles. You can
batch-convert these to JPEG format using the technique shown in the <a
href="#running-commands-in-batch">Running Commands in batch</a> section.
Since JPEG/PNG cannot hold the georeferencing information, we supply the
<code>WORLDFILE=YES</code> creation option.</p>
<pre><code>gdal_translate -of JPEG &lt;input_tile&gt;.tif &lt;input_tile&gt;.jpg -co WORLDFILE=YES</code></pre>
<p>This will create a sidecar file with the <code>.wld</code> extension
that will store the georeferencing information for each tile. GDAL will
automatically apply the georeferencing information to the JPEG tile as
long this file exists in the same directory. This way, you can make
inference using the JPG tiles, and use the <code>.wld</code> files with
your output to automatically georeference and mosaic the results.</p>
</div>
<div id="extracting-projection-information-from-a-raster"
class="section level2">
<h2>Extracting Projection Information from a Raster</h2>
<p>Sometimes you may need to extract and preserve georeferencing
information from a raster to be used later or with a different file. A
typical use case is Deep Learning - where you need to convert your
georeferenced tile (i.e. a GeoTIFF file) into a PNG or JPEG tile. If you
used <code>gdal_retile.py</code> as shown in the <a
href="#splitting-a-mosaic-into-tiles">previous section</a>, you will
have a <em>World File</em> accompanying each tile. But many times, you
only have the original GeoTIFF file and the resulting PNG tile. To copy
the georeferencing information from the GeoTIFF and apply it to the PNG,
you can use the following process.</p>
<p>Let’s say we have a georeferenced tile named
<code>tile_1_1.tif</code> and a annotated version of this tile from a
training dataset as a non-georeferenced tile
<code>tile_1_1_annotated.png</code>. We want to georeference this PNG
file using the projection and extent of the GeoTIFF file.</p>
<p><img src="images/gdal/extract_projection.png" width="75%" style="display: block; margin: auto;" /></p>
<p>We can extract the extent and resolution of the original GeoTIFF
using the <a
href="http://geotiff.maptools.org/listgeo.html"><code>listgeo</code></a>
tool. This tool is already part of the standard GDAL conda distribution.
We will extract the world file using the <code>-tfw</code> flag that
generates an ESRI world file.</p>
<pre><code>listgeo -tfw tile_1_1.tif</code></pre>
<p>You will see that a new file named <code>tile_1_1.tfw</code> is
generated alongside the original GeoTIFF. Next we extract the projecton
information using <a
href="https://gdal.org/programs/gdalsrsinfo.html"><code>gdalsrsinfo</code></a>
command. This command prints the projection information in a variety of
supported formats. We save the output to a file with a <code>.prj</code>
extension.</p>
<pre><code>gdalsrsinfo tile_1_1.tif &gt; tile_1_1.prj</code></pre>
<p>The <code>tile_1_1.tfw</code> and <code>tile_1_1.prj</code> contain
all the information we need to georeference the PNG tile.</p>
<p>Let’s convert the PNG to a GeoTIFF file and assign the projection of
the original tile.</p>
<pre><code>gdal_translate -a_srs tile_1_1.prj tile_1_1_annotated.png tile_1_1_annotated.tif</code></pre>
<p>The resulting file contains the projection but the extents are not
correct. We can use the <a
href="http://geotiff.maptools.org/geotifcp.html"><code>geotifcp</code></a>
tool to apply the extents from the world file to the GeoTIFF. This tool
is also part of the standard GDAL conda distribution.</p>
<pre><code>geotifcp -e tile_1_1.tfw tile_1_1_annotated.tif tile_1_1_annotated_georeferenced.tif</code></pre>
</div>
<div id="merging-files-with-different-resolutions"
class="section level2">
<h2>Merging Files with Different Resolutions</h2>
<p>If you had a bunch of tiles that you wanted to merge, but some tiles
had a different resolution, you can use specify the
<code>-resolution</code> flag with <code>gdalbuildvrt</code> to ensure
the output file has the expected resolution.</p>
<p>Continuing the example from the <a
href="#processing-aerial-imagery">Processing Aerial Imagery</a> section,
we can create a virtual raster and specify the <code>resolution</code>
flag</p>
<pre><code>gdalbuildvrt -input_file_list filelist.txt naip.vrt -resolution highest -r bilinear</code></pre>
<p>Translating this file using <code>gdal_translate</code> or subsetting
it with <code>gdalwarp</code> will result in a mosaic with the highest
resolution from the source tiles.</p>
</div>
<div id="calculate-pixel-wise-statistics-over-multiple-rasters"
class="section level2">
<h2>Calculate Pixel-Wise Statistics over Multiple Rasters</h2>
<p><code>gdal_calc.py</code> can compute pixel-wise statistics over many
input rasters or multi-band rasters. Starting GDAL v3.3, it supports the
full range of numpy functions, such as <code>numpy.average()</code>,
<code>numpy.sum()</code> etc.</p>
<p>Here’s an example showing how to compute the per-pixel total from 12
different input rasters. The <code>prism</code> folder in your data
package contains 12 rasters of precipitation over the continental US. We
will compute pixel-wise total precipitation from these rasters. When you
read multiple rasters using the same input flag <code>-A</code>,
gdal_calc.py creates a 3D numpy array. It can then be reduced along the
axis 0 to produce totals.</p>
<pre><code>cd prism</code></pre>
<pre><code>gdal_calc.py \
    -A PRISM_ppt_stable_4kmM3_201701_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201702_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201703_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201704_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201705_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201706_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201707_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201708_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201709_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201710_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201711_bil.bil \
    -A PRISM_ppt_stable_4kmM3_201712_bil.bil \
    --calc=&#39;numpy.sum(A, axis=0)&#39; \
    --outfile total.tif</code></pre>
<p>Currently, <code>gdal_calc.py</code> doesn’t support reading
multi-band rasters as a 3D array. So if you want to apply a similar
computation on a multi-band raster, you’ll have to specify each band
separately. Let’s say, we want to calculate the pixel-wise average value
from the RGB composite created in the <a
href="#merging-individual-bands-into-rgb-composite">Merging individual
bands into RGB composite</a> section. We can use the command as
follows.</p>
<pre><code>gdal_calc.py \
  -A rgb.tif --A_band=1 \
  -B rgb.tif --B_band=2 \
  -C rgb.tif --C_band=3 \
  --calc=&#39;(A+B+C)/3&#39; \
  --outfile mean.tif</code></pre>
</div>
<div id="extracting-values-from-a-raster" class="section level2">
<h2>Extracting Values from a Raster</h2>
<p>A useful tool called <a
href="https://gdal.org/programs/gdallocationinfo.html"><code>gdallocationinfo</code></a>
comes with the GDAL suite that can do point lookups from the raster at
one or more pairs of coordinates. Combined with GDAL’s capabilities to
stream data from cloud datasets with the <a
href="https://gdal.org/user/virtual_file_systems.html">Virtual File
System</a>, you can efficiently lookup pixel values from without having
to load the entire raster into memory.</p>
<p>For example, we have a large (8GB) single-band Cloud-Optimized
GeoTiff (COG) file on a Google Cloud Storage bucket. This file is a
global mosaic of VIIRS Nighttime Lights for the year 2021 and the pixel
values are the radiance values.</p>
<div class="figure" style="text-align: center">
<img src="images/gdal/ntl_query1.png" alt="VIIRS Nighttime Lights 2021" width="75%" />
<p class="caption">
VIIRS Nighttime Lights 2021
</p>
</div>
<p>To access this file, we use the <code>/vsigs/</code> (Google Cloud
Storage files) handler and provide the path in form of
<code>/vgigs/&lt;bucket_name&gt;/&lt;file_name&gt;</code>. This
particular file is public, so we add the config option
<code>--config GS_NO_SIGN_REQUEST YES</code>.</p>
<pre><code>gdalinfo /vsigs/spatialthoughts-public-data/ntl/viirs/viirs_ntl_2021_global.tif --config GS_NO_SIGN_REQUEST YES</code></pre>
<p>We are successfully able to open and lookup the metadata of this
file. Now let’s query the pixel value at a single coordinate using
<code>gdallocationinfo</code>. We specify the location in WGS84 Lon/Lat
format, so use the <code>-wgs84</code> option.</p>
<pre><code>gdallocationinfo -valonly /vsigs/spatialthoughts-public-data/ntl/viirs/viirs_ntl_2021_global.tif -wgs84 77.5946 12.9716 --config GS_NO_SIGN_REQUEST YES</code></pre>
<p>You can also lookup values of multiple points from a file. Let’s say
we have a text file called <code>coordinates.txt</code> with the
following 2 coordinates.</p>
<pre><code>77.5946 12.9716
77.1025 28.7041</code></pre>
<p>We can lookup the pixel values at these coordinates by supplying this
to the <code>gdallocationinfo</code> command. We also supply the
<code>-xml</code> option so the output is structured and can be used for
post processing.</p>
<pre><code>cat coordinates.txt | gdallocationinfo /vsigs/spatialthoughts-public-data/ntl/viirs/viirs_ntl_2021_global.tif \
  -wgs84 --config GS_NO_SIGN_REQUEST YES -xml</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/ntl_query2.png" alt="Querying single or multiple values" width="75%" />
<p class="caption">
Querying single or multiple values
</p>
</div>
</div>
<div id="masking-values-using-a-binary-raster" class="section level2">
<h2>Masking Values using a Binary Raster</h2>
<p>Often we have binary images representing a data mask. We can use
<code>numpy.where()</code> function with <code>gdal_calc.py</code> to
mask pixels from any raster with a mask image.</p>
<p>Let’s say we have a <code>binary.tif</code> containing pixel values 0
and 1. We now want to set all pixels from <code>merged.tif</code> to No
Data where the <code>binary.tif</code> is 0. Assuming, we want to use
<strong>-32768</strong> as the <em>No Data</em> value, we can use a
command like below.</p>
<pre><code>gdal_calc.py -A merged.tif -B binary.tif \
  --calc=&quot;numpy.where(B==1, A, -32768)&quot; \
  --NoDataValue -32768 --outfile masked.tif</code></pre>
<p>This command says <em>Wherever the value of B raster is 1, the output
should be the pixel values from A else it should be -32768</em>. Since
we are also setting the <code>-NoDataValue</code> to -32768, the command
effectively sets all pixels where the condition doesn’t match (B != 1)
to NoData.</p>
<p><img src="images/gdal/binary_mask.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="raster-to-vector-conversion" class="section level2">
<h2>Raster to Vector Conversion</h2>
<p>GDAL comes with the <code>gdal_polygonize.py</code> allowing us to
convert rasters to vector layers. Let’s say we want to extract the
coordinates of the highest elevation from the merged raster in the <a
href="#merging-tiles">Merging Tiles</a> section. Querying the raster
with <code>gdalinfo -stats</code> shows us that the highest pixel value
is <strong>8748</strong>.</p>
<p>We can use <code>gdal_calc.py</code> to create a raster using the
condition to match only the pixels with that value.</p>
<pre><code>gdal_calc.py --calc &#39;A==8748&#39; -A merged.vrt --outfile everest.tif --NoDataValue=0</code></pre>
<p>The result of a boolean expression like above will be a raster with 1
and 0 pixel values. As we set the NoData to 0, we only have 1 pixel with
value 1 where the condition matched. We can convert it to a vector using
<code>gdal_polygonize.py</code>.</p>
<pre><code>gdal_polygonize.py everest.tif everest.shp</code></pre>
<p>If we want to extract the centroid of the polygon and print the
coordinates, we can use <code>ogrinfo</code> command.</p>
<pre><code>ogrinfo everest.shp -sql &#39;SELECT AsText(ST_Centroid(geometry)) from everest&#39; -dialect SQLite</code></pre>
</div>
<div id="viewshed-analysis" class="section level2">
<h2>Viewshed Analysis</h2>
<p>The <code>gdal_viewshed</code> command can do visibility analysis
using elevation rasters. This is a very useful analysis for many
applications including urban planning and telecommunications. We can
take the London 1m DSM dataset and carry out the visibility analysis
from a location.</p>
<p>We will determine all the areas of London that are visible from the
top of the <a href="https://en.wikipedia.org/wiki/Tower_42">Tower 42</a>
building. This is a skyscraper located in the city of London.</p>
<p>We take the merged DSM created for <a
href="https://courses.spatialthoughts.com/gdal-tools.html#assignment">Assignment
1</a> and generate a viewshed.</p>
<p>The CRS of the dataset is EPSG:27700 so we need to get the observer
location coordinates in this CRS. We can use the
<code>gdaltransform</code> command to convert the Lat/Lon coordinates to
the coordinates in the target CRS. Run the command below and press
enter.</p>
<pre><code>gdaltransform -s_srs EPSG:4326 -t_srs EPSG:27700</code></pre>
<p>The command takes input from the terminal. Enter the X and Y
coordinate as follows</p>
<pre><code>-0.083738 51.515178</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/gdaltransform.png" alt="Results of Viewshed Analysis" width="75%" />
<p class="caption">
Results of Viewshed Analysis
</p>
</div>
<p>The output of the command are the X and Y coordinates
<strong>533061.985055201 181323.948402008</strong>. We round them off
and use it in the <code>gdal_viewshed</code> command.</p>
<pre><code>gdal_viewshed -b 1 -ox 533062 -oy 181324 -oz 10 -md 100000.0 -f GTiff -co COMPRESS=DEFLATE -co PREDICTOR=2 merged.tif viewshed_tower42.tif</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/viewshed.png" alt="Results of Viewshed Analysis" width="75%" />
<p class="caption">
Results of Viewshed Analysis
</p>
</div>
</div>
<div id="working-with-kml-files" class="section level2">
<h2>Working with KML Files</h2>
<p>Keyhole Markup Language (KML) is a XML-based file format primarily
used by Google Earth. Often time, GIS users want to export their data to
KML for visualizing it in Google Earth. You may also want to extract
data from KML files or convert them into other spatial formats used in
GIS. The <a href="https://gdal.org/drivers/vector/kml.html">GDAL KML
Driver</a> can both read and write KML files and provides many options
to make the conversion compatible.</p>
<div id="exporting-data-to-kml-files" class="section level3">
<h3>Exporting Data to KML files</h3>
<p>Let’s take the <code>metro_stations</code> layer from the
<code>spatial_query.gpkg</code> file in your data package and export it
to a KML file <code>metro_stations.kml</code>.</p>
<pre><code>ogr2ogr -f KML metro_stations.kml spatial_query.gpkg metro_stations </code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/kml1.png" alt="KML Export without NameField" width="75%" />
<p class="caption">
KML Export without NameField
</p>
</div>
<p>While the above command works, you will notice that when you open the
resulting file in Google Earth, the placemarks for each feature doesn’t
have any labels. This is because the KML format expects a field called
<strong>Name</strong> in the layer which is used as the label for each
placemark. If your data layer does not have such a field, you can supply
an alternate field name that will be used as labels using the
<code>-dsco</code> option. The <code>metro_stations</code> layer has a
field named <code>station</code> which we can use as the name field.</p>
<pre><code>ogr2ogr -f KML metro_stations.kml spatial_query.gpkg metro_stations -dsco NameField=station</code></pre>
<div class="figure" style="text-align: center">
<img src="images/gdal/kml2.png" alt="KML Export with NameField" width="75%" />
<p class="caption">
KML Export with NameField
</p>
</div>
</div>
<div id="converting-kml-files-to-other-formats" class="section level3">
<h3>Converting KML Files to Other Formats</h3>
<p>The KML file format supports having multiple data layers within the
same KML file. We will now learn how to extract a specific data layer
and convert it to a shapefile. GDAL supports reading data from a URL
using the <a
href="https://gdal.org/user/virtual_file_systems.html">Virtual File
System</a>. We can read a KML file from the internet using the
<code>vsicurl/</code> prefix.</p>
<pre><code>ogrinfo /vsicurl/https://developers.google.com/kml/documentation/KML_Samples.kml</code></pre>
<p><img src="images/gdal/kml3.png" width="75%" style="display: block; margin: auto;" /></p>
<p>Let’s read the <code>Paths</code> layer</p>
<pre><code>ogrinfo /vsicurl/https://developers.google.com/kml/documentation/KML_Samples.kml Paths</code></pre>
<p><img src="images/gdal/kml4.png" width="75%" style="display: block; margin: auto;" /></p>
<p>To extract the <code>Paths</code> layer from this KML file, we can
use <code>ogr2ogr</code> command. The default options create many
unwanted fields in the output. We can select a subset of the input
fields using the <code>-select</code> option.</p>
<pre><code>ogr2ogr -f &quot;ESRI Shapefile&quot; paths.shp /vsicurl/https://developers.google.com/kml/documentation/KML_Samples.kml Paths -select &quot;NAME,Description&quot;</code></pre>
<p><img src="images/gdal/kml5.png" width="75%" style="display: block; margin: auto;" /></p>
<p>You can also convert a KML layer to a CSV file. The <a
href="https://gdal.org/drivers/vector/csv.html">GDAL CSV Driver</a> is
able to extract the geometry of features using the <code>GEOMETRY</code>
layer creation option. Let’s convert the <code>Placemark</code> layer
from the <code>KML_Samples.kml</code> to a CSV file with
<strong>X</strong>, <strong>Y</strong> and <strong>Z</strong> columns
extracted from the geometry.</p>
<pre><code>ogr2ogr -f CSV points.csv /vsicurl/https://developers.google.com/kml/documentation/KML_Samples.kml Placemarks -lco GEOMETRY=AS_XYZ</code></pre>
<p><img src="images/gdal/kml6.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="kml-vs.-libkml-drivers" class="section level3">
<h3>KML vs. LIBKML Drivers</h3>
<p>If your GDAL binaries are compiled with support for the <a
href="https://gdal.org/drivers/vector/libkml.html#vector-libkml">LIBKML
Driver</a>, it is preferable to use it over the <strong>KML</strong>
driver. The <strong>LIBKML</strong> driver supports many more options
and allows you to create fully featured KMLs.</p>
<p>Below is an example of data conversion using the LIBKML driver. To
specify the name field, the LIBKML driver uses an environment variable
called <code>LIBKML_NAME_FIELD</code> that can be specified with the
<code>--config</code> option</p>
<pre><code>ogr2ogr -f LIBKML metro_stations.kml spatial_query.gpkg metro_stations --config LIBKML_NAME_FIELD station</code></pre>
<p>If your GDAL version has both KML and LIBKML drivers, OGR will prefer
the LIBKML driver. To force OGR to use the KML driver for reading files,
you can add <code>--config OGR_SKIP LIBKML</code> to your command.</p>
</div>
</div>
<div id="group-statistics" class="section level2">
<h2>Group Statistics</h2>
<p>We can use SQL GROUP BY clause in <code>ogr2ogr</code> to generate
summary statistics from a layer. Let’s first create a geopackage from
the <code>worldcities.csv</code> layer.</p>
<pre><code>ogr2ogr -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 \
  -sql &quot;SELECT city, country, CAST(population as integer) as population from worldcities&quot; \
  worldcities.gpkg worldcities.csv -nln worldcities</code></pre>
<p>We have a layer <code>worldcities.gpkg</code> that has
<strong>population</strong> and <strong>country</strong> columns. Let’s
calculate the total population per country. We can save the resulting
statistics as an Excel sheet.</p>
<pre><code>ogr2ogr stats.xlsx worldcities.gpkg \
  -sql &quot;SELECT country, sum(population) as total_population from worldcities GROUP BY country&quot;</code></pre>
</div>
<div id="using-virtual-layers" class="section level2">
<h2>Using Virtual Layers</h2>
<p>Similar to GDAL, OGR also supports <a
href="https://gdal.org/drivers/vector/vrt.html">Virtual File Format
(VRT)</a>. Compared to the raster version, the OGR Virtual Driver is
much more capable and can be used for on-the-fly data transformations.
Multiple data layers can be combined into a single <em>virtual</em>
layer using the XML-based <code>.vrt</code> format files. VRT files are
also used to configure reading tabular data into spatial data
formats.</p>
<div id="read-geonames-files" class="section level3">
<h3>Read Geonames Files</h3>
<p>Your data package contains 3 large text files from Geonames in the
<code>geonames</code> folder. These are plain-text files in a
Tab-Separated Values (TSV) format. Change to the <code>geonames</code>
directory.</p>
<pre><code>cd geonames</code></pre>
<p>Let’s try reading one of the files <code>CA.txt</code> - which has
over 300K records of all placenames in Canada. To read this file, we
need to create a new file called <code>CA.vrt</code> with the following
content. Save the file in the same <code>geonames</code> directory.</p>
<pre><code>&lt;OGRVRTDataSource&gt;
        &lt;OGRVRTLayer name=&quot;CA&quot;&gt;
            &lt;SrcDataSource&gt;CSV:CA.txt&lt;/SrcDataSource&gt;
            &lt;SrcLayer&gt;CA&lt;/SrcLayer&gt;
        &lt;/OGRVRTLayer&gt;
&lt;/OGRVRTDataSource&gt;</code></pre>
<p><img src="images/gdal/geonames1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Let’s check if OGR can read the source text file via the newly
created <code>CA.vrt</code> file.</p>
<pre><code>ogrinfo -al -so CA.vrt</code></pre>
<p><img src="images/gdal/geonames2.png" width="60%" style="display: block; margin: auto;" /></p>
<p>The <code>ogrinfo</code> command was able to successfully read the
data and show us the summary of the attributes as well as the total
feature count. Note that OGR has built-in support for the geonames file
format. So it was able to correctly detect the geometry columns without
us specifying it. For other datasets, you will have to specify the
geometry columns explicitly via the <code>&lt;GeometryField&gt;</code>
attribute in the VRT file.</p>
</div>
<div id="applying-filters" class="section level3">
<h3>Applying Filters</h3>
<p>VRT format supports applying SQL queries on the source layer using
the <code>&lt;SrcSQL&gt;</code> field. This allows us to create an
on-the-fly filter that reads only a subset of the data. Update the
<code>CA.vrt</code> with the following content.</p>
<pre><code>&lt;OGRVRTDataSource&gt;
        &lt;OGRVRTLayer name=&quot;CA&quot;&gt;
            &lt;SrcDataSource&gt;CSV:CA.txt&lt;/SrcDataSource&gt;
            &lt;SrcLayer&gt;CA&lt;/SrcLayer&gt;
            &lt;SrcSQL&gt;select * from CA where &quot;FEATCLASS&quot; = &#39;T&#39;&lt;/SrcSQL&gt;
        &lt;/OGRVRTLayer&gt;
&lt;/OGRVRTDataSource&gt;</code></pre>
<p><img src="images/gdal/geonames3.png" width="60%" style="display: block; margin: auto;" /></p>
<p>The VRT file now contains a SQL query to select only the mountain
features from the source file. Let’s run <code>ogrinfo</code> again and
check the output.</p>
<pre><code>ogrinfo -al -so CA.vrt</code></pre>
<p><img src="images/gdal/geonames4.png" width="60%" style="display: block; margin: auto;" /></p>
<p>You will see that the output contains a subset of features, even
though we never changed the source data.</p>
</div>
<div id="merging-files" class="section level3">
<h3>Merging Files</h3>
<p>The real power of the VRT file format lies in its ability to
dynamically combine multiple data sources into a single data layer. We
can adapt the previously created file and use
<code>&lt;OGRVRTUnionLayer&gt;</code> to create a single layer from the
3 separate text files. Save the following content into a new file named
<code>NA.vrt</code>.</p>
<pre><code>&lt;OGRVRTDataSource&gt;
    &lt;OGRVRTUnionLayer name=&quot;NA&quot;&gt;
    
        &lt;OGRVRTLayer name=&quot;CA&quot;&gt;
            &lt;SrcDataSource&gt;CSV:CA.txt&lt;/SrcDataSource&gt;
            &lt;SrcLayer&gt;CA&lt;/SrcLayer&gt;
            &lt;SrcSQL&gt;select * from CA where &quot;FEATCLASS&quot; = &#39;T&#39;&lt;/SrcSQL&gt;
        &lt;/OGRVRTLayer&gt;
    
        &lt;OGRVRTLayer name=&quot;MX&quot;&gt;
            &lt;SrcDataSource&gt;CSV:MX.txt&lt;/SrcDataSource&gt;
            &lt;SrcLayer&gt;MX&lt;/SrcLayer&gt;
            &lt;SrcSQL&gt;select * from MX where &quot;FEATCLASS&quot; = &#39;T&#39;&lt;/SrcSQL&gt;
        &lt;/OGRVRTLayer&gt;
    
        &lt;OGRVRTLayer name=&quot;US&quot;&gt;
            &lt;SrcDataSource&gt;CSV:US.txt&lt;/SrcDataSource&gt;
            &lt;SrcLayer&gt;US&lt;/SrcLayer&gt;
            &lt;SrcSQL&gt;select * from US where &quot;FEATCLASS&quot; = &#39;T&#39;&lt;/SrcSQL&gt;
        &lt;/OGRVRTLayer&gt;
    
    &lt;/OGRVRTUnionLayer&gt; 
&lt;/OGRVRTDataSource&gt;</code></pre>
<p><img src="images/gdal/geonames5.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Let’s now translate the <code>NA.vrt</code> to a GeoPackage using the
<code>ogr2ogr</code> command.</p>
<pre><code>ogr2ogr -f GPKG NA.gpkg NA.vrt -a_srs EPSG:4326</code></pre>
<blockquote>
<p>This operation requires a lot of processing and may take a few
minutes. You can add the <code>--config GDAL_CACHEMAX 512</code> option
to speed up the process. See <a
href="#tips-for-improving-performance">Tips for Improving
Performance</a> section for more details.</p>
</blockquote>
<p>This command reads all 3 text files, filters them for matching
features, combines them and writes out a spatial layer containing all
mountains in North America.</p>
<p><img src="images/gdal/geonames6.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="resources" class="section level1">
<h1>Resources</h1>
<ul>
<li><a href="https://twitter.com/gdaltips">GDAL Tips</a>
<code>@gdaltips</code> on Twitter</li>
<li>A Gentle Introduction to GDAL by Robert Simmon <a
href="https://medium.com/planet-stories/a-gentle-introduction-to-gdal-part-1-a3253eb96082">Part-1</a>,
<a
href="https://medium.com/@robsimmon/a-gentle-introduction-to-gdal-part-2-map-projections-gdalwarp-e05173bd710a">Part-2</a>,
<a
href="https://medium.com/planet-stories/a-gentle-introduction-to-gdal-part-3-geodesy-local-map-projections-794c6ff675ca">Part-3</a>,
<a
href="https://medium.com/planet-stories/a-gentle-introduction-to-gdal-part-4-working-with-satellite-data-d3835b5e2971">Part-4</a>,
<a
href="https://medium.com/@robsimmon/a-gentle-introduction-to-gdal-part-5-shaded-relief-ec29601db654">Part-5</a>,
<a
href="https://medium.com/@robsimmon/a-gentle-introduction-to-gdal-part-6-1-visualizing-data-8e6e7d6ef641">Part-6</a>,
<a
href="https://medium.com/@robsimmon/a-gentle-introduction-to-gdal-part-7-transforming-data-178df8640dd2">Part-7</a></li>
<li><a
href="https://datascienceatthecommandline.com/2e/chapter-1-introduction.html">Data
Science at the Command Line</a> by Jeroen Janssens</li>
</ul>
</div>
<div id="data-credits" class="section level1">
<h1>Data Credits</h1>
<ul>
<li>Landsat: Landsat-8 image courtesy of the U.S. Geological Survey.
Image downloaded from <a
href="https://console.cloud.google.com/marketplace/details/usgs-public-data/landast">Google
Cloud Platform</a> and pre-processed using <a
href="https://fromgistors.blogspot.com/p/semi-automatic-classification-plugin.html">Semi
Automatic Classification Plugin from QGIS</a></li>
<li>Earth at Night image: Credit: NASA Earth Observatory/NOAA NGDC.
Earth at Night flat hi-resolution map downloaded from <a
href="https://earthobservatory.nasa.gov/features/NightLights/page3.php">NASA
earth observatory</a></li>
<li>William Mackenzie 1870 map of Southern India: out-of-copyright
scanned map downloaded from <a
href="http://www.hipkiss.org/data/maps.html">Hipkiss’s Scanned Old
Maps</a></li>
<li>NAIP 2016 Aerial Imagery for California: The National Agriculture
Imagery Program (NAIP). USDA-FSA-APFO Aerial Photography Field Office.
Downloaded from <a
href="https://nrcs.app.box.com/v/naip/folder/18144379349">NRCS</a></li>
<li>London 1m DSM. Downloaded from Defra Data Services Platform. ©
Environment Agency copyright and/or database right 2019. All rights
reserved.</li>
<li>Melbourne Metro Stations: © 2019 <a
href="https://data.melbourne.vic.gov.au/">The City of Melbourne Open
Data Portal</a>. Data provided by Metro Trains Melbourne</li>
<li>Melbourne Bars and Pubs: © 2019 <a
href="https://data.melbourne.vic.gov.au/">The City of Melbourne Open
Data Portal</a>. Data provided by Census of Land Use and Employment
(CLUE)</li>
<li>VIIRS Annual VNL V2 for 2021. C. D. Elvidge, M. Zhizhin, T. Ghosh,
F-C. Hsu, “Annual time series of global VIIRS nighttime lights derived
from monthly averages: 2012 to 2019”, Remote Sensing (In press)</li>
</ul>
</div>
<div id="license" class="section level1">
<h1>License</h1>
<p>This course material is licensed under a <a
href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons
Attribution-NonCommercial 4.0 International License</a>. You are free to
use the material for any non-commercial purpose. Kindly give appropriate
credit to the original author.</p>
<p>If you would like to utilize these materials as part of a commercial
offering, you can purchase a <em>Trainer License</em> for a small
fee.</p>
<p>Please <a href="https://spatialthoughts.com/contact/">contact us</a>
for pricing and terms.</p>
<p>© 2020 Ujaval Gandhi <a
href="http://spatialthoughts.com">www.spatialthoughts.com</a></p>
<hr />
<p><strong>This course is offered as an instructor-led online class.
Visit <a href="https://spatialthoughts.com/events/">Spatial Thoughts</a>
to know details of upcoming sessions.</strong></p>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Code reference <a
href="https://gis.stackexchange.com/questions/255537/merging-hillshade-dem-data-into-color-relief-single-geotiff-with-qgis-and-gdal"
class="uri">https://gis.stackexchange.com/questions/255537/merging-hillshade-dem-data-into-color-relief-single-geotiff-with-qgis-and-gdal</a><a
href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

<!-- Comment Section Powered by utterances -->
<div id="comments">
  <hr />
  <p>If you want to report any issues with this page, please comment below.</p>
<script src="https://utteranc.es/client.js"
        repo="spatialthoughts/courses"
        issue-term="title"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
</div>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
