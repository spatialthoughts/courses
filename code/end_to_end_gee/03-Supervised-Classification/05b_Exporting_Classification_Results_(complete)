// Load training samples
// This was created by exporting the merged 'gcps' collection
// using Export.table.toAsset()
var gcps = ee.FeatureCollection('projects/spatialthoughts/assets/e2e/exported_gcps');

// Load the region boundary of a basin
var boundary = ee.FeatureCollection('projects/spatialthoughts/assets/e2e/basin_boundary');
var geometry = boundary.geometry();
Map.centerObject(geometry);

var rgbVis = {
  min: 0.0,
  max: 3000,
  bands: ['B4', 'B3', 'B2'],
};
 
var year = 2019;
var startDate = ee.Date.fromYMD(year, 1, 1);
var endDate = startDate.advance(1, 'year');

var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED');

var filtered = s2
  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))
  .filter(ee.Filter.date(startDate, endDate))
  .filter(ee.Filter.bounds(geometry));

// Load the Cloud Score+ collection
var csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED');
var csPlusBands = csPlus.first().bandNames();

// We need to add Cloud Score + bands to each Sentinel-2
// image in the collection
// This is done using the linkCollection() function
var filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands);

// Function to mask pixels with low CS+ QA scores.
function maskLowQA(image) {
  var qaBand = 'cs';
  var clearThreshold = 0.5;
  var mask = image.select(qaBand).gte(clearThreshold);
  return image.updateMask(mask);
}

var filteredMasked = filteredS2WithCs
  .map(maskLowQA)
  .select('B.*');

var composite = filteredMasked.median();

// Use Satellite Embeddings as Features

var embeddings = ee.ImageCollection('GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL');

var filteredEmbeddings = embeddings
  .filter(ee.Filter.date(startDate, endDate))
  .filter(ee.Filter.bounds(geometry));
  
var embeddingsImage = filteredEmbeddings.mosaic();

// Train a classifier.

// Add a random column and split the GCPs into training and validation set
var gcps = gcps.randomColumn();

// This being a simpler classification, we take 60% points
// for validation. Normal recommended ratio is
// 70% training, 30% validation
var trainingGcp = gcps.filter(ee.Filter.lt('random', 0.6));
var validationGcp = gcps.filter(ee.Filter.gte('random', 0.6));

// Overlay the point on the image to get training data.
var training = embeddingsImage.sampleRegions({
  collection: trainingGcp,
  properties: ['landcover'],
  scale: 10,
  tileScale: 16
});


var classifier = ee.Classifier.smileKNN()
.train({
  features: training,  
  classProperty: 'landcover',
  inputProperties: embeddingsImage.bandNames()
});

// Classify the image.
var classified = embeddingsImage.classify(classifier);

var palette = ['#cc6d8f', '#ffc107', '#1e88e5', '#004d40' ];
Map.addLayer(classified.clip(geometry), {min: 0, max: 3, palette: palette}, 'Classification');

// Accuracy Assessment

// Use classification map to assess accuracy using the validation fraction
// of the overall training set created above.
var test = classified.sampleRegions({
  collection: validationGcp,
  properties: ['landcover'],
  tileScale: 16,
  scale: 10,
});

var testConfusionMatrix = test.errorMatrix('landcover', 'classification');

// If you are trying to classify a large region, you may get errors when trying
// to print or display the results interactively.

// For large computations requiring more than 5 minutes, it is recommended
// to Export the results.

// To avoid these errors, remove all print() statements and Map.addLayer()
// calls and export the data first.

// Exporting Data

// For exporing data - such as accuracy or confusion matrix - turn them
// into a FeatureCollection first.

var fc = ee.FeatureCollection([
  ee.Feature(geometry, {
    'accuracy': testConfusionMatrix.accuracy(),
    'matrix': testConfusionMatrix.array()
  })
]);

Export.table.toDrive({
  collection: fc,
  description: 'Accuracy_Assessment_Export',
  folder: 'earthengine',
  fileNamePrefix: 'accuracy',
  fileFormat: 'CSV'
});

// Exporting Images

// Exporting Images as GeoTIFF files

// For images having integers (such as class numbers)
// we cast the image to floating point data type which
// allows the masked values to be saved as NaN values
// in the GeoTIFF format.
// You can set these to actual NoData values using
// GDAL tools after the export
// gdal_translate -a_nodata 'nan' input.tif output.tif
Export.image.toDrive({
  image: classified.clip(geometry).toFloat(),
  description: 'Classified_Image_Export_Drive',
  folder: 'earthengine',
  fileNamePrefix: 'classified',
  region: geometry,
  scale: 10,
  maxPixels: 1e10
});

// Exporting Images as Assets

// If you want to visuaize or use the results in GEE,
// you can export them as Assets

// Replace this with your asset folder
// The folder must exist before exporting
var exportFolder = 'projects/spatialthoughts/assets/e2e/';

// Export Composite
var compositeExportImage = 'composite';
var compositeExportImagePath = exportFolder + compositeExportImage;

Export.image.toAsset({
  image: composite.clip(geometry),
  description: 'Composite_Image_Export_Asset',
  assetId: compositeExportImagePath,
  region: geometry,
  scale: 10,
  maxPixels: 1e10
});

// Export Classified Image
var classifiedExportImage = 'embeddings_classification';
var classifiedExportImagePath = exportFolder + classifiedExportImage;

Export.image.toAsset({
  image: classified.clip(geometry),
  description: 'Classified_Image_Export_Asset',
  assetId: classifiedExportImagePath,
  region: geometry,
  scale: 10,
  pyramidingPolicy: 'MODE',
  maxPixels: 1e10
});