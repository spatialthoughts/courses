{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a244534-c0a1-41b4-9f73-2087eb72b030",
      "metadata": {
        "id": "9a244534-c0a1-41b4-9f73-2087eb72b030"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Xarray is an evolution of rasterio and is inspired by libraries like pandas to work with raster datasets. It is particularly suited for working with multi-dimensional time-series raster datasets. It also integrates tightly with dask that allows one to scale raster data processing using parallel computing. XArray provides [Plotting Functions](https://xarray.pydata.org/en/stable/user-guide/plotting.html) based on Matplotlib.\n",
        "\n",
        "In this section, we will learn about XArray basics and learn how to work with a time-series of Sentinel-2 satellite imagery to create and visualize a median composite image."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c4204d0-acda-418f-b38a-7d5f2be15eca",
      "metadata": {
        "id": "2c4204d0-acda-418f-b38a-7d5f2be15eca"
      },
      "source": [
        "## Setup and Data Download\n",
        "\n",
        "The following blocks of code will install the required packages and download the datasets to your Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jf7cnFbts_ES",
      "metadata": {
        "id": "jf7cnFbts_ES"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install pystac-client odc-stac rioxarray dask jupyter-server-proxy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe6c71dd-37df-47af-9019-d012cc9b5e59",
      "metadata": {
        "id": "fe6c71dd-37df-47af-9019-d012cc9b5e59"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pystac_client\n",
        "from odc import stac\n",
        "import xarray as xr\n",
        "import rioxarray as rxr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dA58tdUJJAni",
      "metadata": {
        "id": "dA58tdUJJAni"
      },
      "source": [
        "## Dask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wdl41A5UI7vY",
      "metadata": {
        "id": "Wdl41A5UI7vY"
      },
      "source": [
        "[`Dask`](https://www.dask.org/) is a python library to run your computation in parallel across many machines. Dask has built-in support for key geospatial packages like XArray and Pandas allowing you to scale your computation easily. You can choose to run your code in parallel on your laptop, a machine in the cloud, local or cloud cluster of machines etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I2KA7L44UDyj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "I2KA7L44UDyj",
        "outputId": "02300240-980a-450e-e37d-d571874c8a03"
      },
      "outputs": [],
      "source": [
        "from dask.distributed import Client\n",
        "client = Client()  # set up local cluster on the machine\n",
        "client"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KZN-5NC0UGxM",
      "metadata": {
        "id": "KZN-5NC0UGxM"
      },
      "source": [
        "f you are running this notebook in Colab, you will need to create and use a proxy URL to see the dashboard running on the local server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LGoGPPD_UFZA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LGoGPPD_UFZA",
        "outputId": "c175db8e-e525-4432-cd8b-05fcfbf51f75"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import output\n",
        "    port_to_expose = 8787  # This is the default port for Dask dashboard\n",
        "    print(output.eval_js(f'google.colab.kernel.proxyPort({port_to_expose})'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qYm2b2t7ut8N",
      "metadata": {
        "id": "qYm2b2t7ut8N"
      },
      "source": [
        "## Spatio Temporal Asset Catalog (STAC)\n",
        "\n",
        "Spatio Temporal Asset Catalog (STAC) is an open standard for specifying and querying geospatial data. Data provider can share catalogs of satellite imagery ,climate datasets, LIDAR data, vector data etc. and specify asset metadata according to the STAC specifications. All STAC catalogs can be queried to find matching assets by time, location or metadata.\n",
        "\n",
        "\n",
        "You can browse all available catalogs at https://stacindex.org/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nL8kqCYovK1S",
      "metadata": {
        "id": "nL8kqCYovK1S"
      },
      "source": [
        "Let's use [Earth Search by Element 84](https://stacindex.org/catalogs/earth-search#/) STAC API Catalog to look for items from the sentinel-2-l2a collection on AWS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CQmDtdO7KXZ8",
      "metadata": {
        "id": "CQmDtdO7KXZ8"
      },
      "outputs": [],
      "source": [
        "catalog = pystac_client.Client.open(\n",
        "    'https://earth-search.aws.element84.com/v1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DfeU1L0HCPN3",
      "metadata": {
        "id": "DfeU1L0HCPN3"
      },
      "source": [
        "We define a location and time of interest to get some satellite imagery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yFB6fP_Cu0Rw",
      "metadata": {
        "id": "yFB6fP_Cu0Rw"
      },
      "outputs": [],
      "source": [
        "latitude = 27.163\n",
        "longitude = 82.608\n",
        "year = 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Eyw63wuevOp-",
      "metadata": {
        "id": "Eyw63wuevOp-"
      },
      "outputs": [],
      "source": [
        "# Define a small bounding box around the chosen point\n",
        "km2deg = 1.0 / 111\n",
        "x, y = (longitude, latitude)\n",
        "r = 1 * km2deg  # radius in degrees\n",
        "bbox = (x - r, y - r, x + r, y + r)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_H_dLmj7KiJO",
      "metadata": {
        "id": "_H_dLmj7KiJO"
      },
      "source": [
        "Search the catalog for matching items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1FdQxCyGKk2l",
      "metadata": {
        "id": "1FdQxCyGKk2l"
      },
      "outputs": [],
      "source": [
        "search = catalog.search(\n",
        "    collections=['sentinel-2-c1-l2a'],\n",
        "    bbox=bbox,\n",
        "    datetime=f'{year}'\n",
        ")\n",
        "items = search.item_collection()\n",
        "items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8x9TV8dWKvPV",
      "metadata": {
        "id": "8x9TV8dWKvPV"
      },
      "source": [
        "We can apply some additional metadata filters to look for images with less cloud cover and granules with less nodata pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y9nSaSiFK0hK",
      "metadata": {
        "id": "y9nSaSiFK0hK"
      },
      "outputs": [],
      "source": [
        "search = catalog.search(\n",
        "    collections=['sentinel-2-c1-l2a'],\n",
        "    bbox=bbox,\n",
        "    datetime=f'{year}',\n",
        "    query={'eo:cloud_cover': {'lt': 30}, 's2:nodata_pixel_percentage': {'lt': 10}}\n",
        ")\n",
        "items = search.item_collection()\n",
        "items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XCNPD7qXLFPL",
      "metadata": {
        "id": "XCNPD7qXLFPL"
      },
      "source": [
        "We can also sort the results by some metadata. Here we sort by cloud cover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l68ZjcOPZGAZ",
      "metadata": {
        "id": "l68ZjcOPZGAZ"
      },
      "outputs": [],
      "source": [
        "search = catalog.search(\n",
        "    collections=['sentinel-2-c1-l2a'],\n",
        "    bbox=bbox,\n",
        "    datetime=f'{year}',\n",
        "    query={'eo:cloud_cover': {'lt': 30}, 's2:nodata_pixel_percentage': {'lt': 10}},\n",
        "    sortby=[{'field': 'properties.eo:cloud_cover', 'direction': 'asc'}]\n",
        "\n",
        ")\n",
        "items = search.item_collection()\n",
        "items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lpzNYT64LZk4",
      "metadata": {
        "id": "lpzNYT64LZk4"
      },
      "source": [
        "## Load STAC Images to XArray"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15iTJmV5CwnP",
      "metadata": {
        "id": "15iTJmV5CwnP"
      },
      "source": [
        "Load the matching images as a XArray Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y7a0SNP30yTd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "Y7a0SNP30yTd",
        "outputId": "a965004b-9e3b-42f6-a695-8237ad90f68d"
      },
      "outputs": [],
      "source": [
        "ds = stac.load(\n",
        "    items,\n",
        "    bands=['red', 'green', 'blue', 'nir', 'scl'],\n",
        "    resolution=10,\n",
        "    chunks={},  # <-- use Dask\n",
        "    groupby='solar_day',\n",
        "    preserve_original_order=True\n",
        ")\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ANUXKKYkMH61",
      "metadata": {
        "id": "ANUXKKYkMH61"
      },
      "source": [
        "Use[ `xarray.Dataset.nbytes`](https://docs.xarray.dev/en/latest/generated/xarray.Dataset.nbytes.html) property to check the size of the loaded dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Aq2WX9RdZzWT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq2WX9RdZzWT",
        "outputId": "16438658-e7e2-4b2b-d3dd-eb3df2120083"
      },
      "outputs": [],
      "source": [
        "print(f'DataSet size: {ds.nbytes/1e6:.2f} MB.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U1Yjq2sNQEib",
      "metadata": {
        "id": "U1Yjq2sNQEib"
      },
      "source": [
        "## Select a Single Scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QR9Gqm0QMnM7",
      "metadata": {
        "id": "QR9Gqm0QMnM7"
      },
      "source": [
        "Let's work with a single scene for now. We will use the first item from our search (the least cloudy scene). When the items are loaded as a XArray Dataset, the `time` dimension is sorted. We get the timestamp of the least cloudy scene and select it from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bxmTBnyvfkBY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "bxmTBnyvfkBY",
        "outputId": "7085e82e-2c26-46d9-cab9-cadbde15e1ed"
      },
      "outputs": [],
      "source": [
        "timestamp = pd.to_datetime(items[0].properties['datetime']).tz_convert(None)\n",
        "scene = ds.sel(time=timestamp)\n",
        "scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r-qSz1dmfw8g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-qSz1dmfw8g",
        "outputId": "61613a52-856e-4e34-f820-6fce2e8229a2"
      },
      "outputs": [],
      "source": [
        "print(f'Scene size: {ds.nbytes/1e6:.2f} MB.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Ub8H4FLNS3S",
      "metadata": {
        "id": "2Ub8H4FLNS3S"
      },
      "source": [
        "This scene is small enough to fit into RAM, so let's call `compute()` to load this into memory. Dask will query the cloud-hosted dataset to fetch the required pixels. As we setup a Dask LocalCluster, the process will be paralellized across all available cores of the machine. Once you run the cell, look at the Dask Diagnostic Dashboard to see the data processing in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3Gp8L7of18k",
      "metadata": {
        "id": "b3Gp8L7of18k"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "scene = scene.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O8zkWD47N3vo",
      "metadata": {
        "id": "O8zkWD47N3vo"
      },
      "outputs": [],
      "source": [
        "scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vgefI7nTuRqb",
      "metadata": {
        "id": "vgefI7nTuRqb"
      },
      "source": [
        "The Sentinel-2 scenes come with NoData value of 0. So we set the correct NoData value before further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1mIFrJ0GuUbx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "1mIFrJ0GuUbx",
        "outputId": "cc699d3a-7b6f-497e-c122-b12efc99f648"
      },
      "outputs": [],
      "source": [
        "scene = scene.where(scene != 0)\n",
        "scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EtWVe_TNN-V5",
      "metadata": {
        "id": "EtWVe_TNN-V5"
      },
      "source": [
        "## Visualize the Scene"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hCzpJQLjOKpO",
      "metadata": {
        "id": "hCzpJQLjOKpO"
      },
      "source": [
        "To visualize our Dataset, we first convert it to a DataArray using the `to_array()` method. All the variables will be converted to a new dimension. Since our variables are image bands, we give the name of the new dimesion as band.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QrjqYog1j7Wj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QrjqYog1j7Wj",
        "outputId": "61aea0f6-fc2b-4bcc-c27f-641467270324"
      },
      "outputs": [],
      "source": [
        "scene_da = scene.to_array('band')\n",
        "scene_da"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KwLtwED1OPUi",
      "metadata": {
        "id": "KwLtwED1OPUi"
      },
      "source": [
        "We can create a low-resolution preview by resampling the DataArray from its native resolution. The raster metadata is stored in the [rio accessor](https://corteva.github.io/rioxarray/stable/rioxarray.html#rioxarray-rio-accessors). This is enabled by the `rioxarray` library which provides geospatial functions on top of xarray."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yKpGIoqeOwzR",
      "metadata": {
        "id": "yKpGIoqeOwzR"
      },
      "outputs": [],
      "source": [
        "print('CRS:', rds.rio.crs)\n",
        "print('Resolution:', rds.rio.resolution())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZvrXP8uOPFiW",
      "metadata": {
        "id": "ZvrXP8uOPFiW"
      },
      "source": [
        "Reproject and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K1LBGnehgDNL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "K1LBGnehgDNL",
        "outputId": "424ff372-be5a-4276-d223-4e5c1b235306"
      },
      "outputs": [],
      "source": [
        "preview = scene_da.rio.reproject(\n",
        "    scene.rio.crs, resolution=300\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "fig.set_size_inches(5,5)\n",
        "preview.sel(band=['red', 'green', 'blue']).plot.imshow(\n",
        "    ax=ax,\n",
        "    robust=True)\n",
        "ax.set_title('RGB Visualization')\n",
        "ax.set_axis_off()\n",
        "ax.set_aspect('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KyCU3Hs6WPpn",
      "metadata": {
        "id": "KyCU3Hs6WPpn"
      },
      "source": [
        "## Save the Scene to Disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UWWTQBvSWO_n",
      "metadata": {
        "id": "UWWTQBvSWO_n"
      },
      "outputs": [],
      "source": [
        "scene_id = items[0].id\n",
        "output_da = scene_da.sel(band=['red', 'green', 'blue'])\n",
        "output_file = f'{scene_id}.tif'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KrCBniRTPfoD",
      "metadata": {
        "id": "KrCBniRTPfoD"
      },
      "source": [
        "Rather than saving it to the temporary machine where Colab is running, we can save it to our own Google Drive. This will ensure the image will be available to us even after existing Google Colab.\n",
        "\n",
        "Run the following cell to authenticate and mount the Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0kaRA4MkjhQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0kaRA4MkjhQ",
        "outputId": "1c283d3f-28dc-44de-9b5e-79aa010cb6f8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FN-taBQGks9X",
      "metadata": {
        "id": "FN-taBQGks9X"
      },
      "outputs": [],
      "source": [
        "drive_folder_root = '/content/drive/MyDrive'\n",
        "output_file_path = os.path.join(drive_folder_root, output_file)\n",
        "output_da.rio.to_raster(output_file_path, compress='LZW')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
